{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"copairs","text":"<p><code>copairs</code> is a Python package for finding groups of profiles based on metadata and calculate mean Average Precision to assess intra- vs inter-group similarities.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install copairs\n</code></pre>"},{"location":"#citation","title":"Citation","text":"<p>If you find this work useful for your research, please cite our paper:</p> <p>Kalinin, A.A., Arevalo, J., Serrano, E., Vulliard, L., Tsang, H., Bornholdt, M., Mu\u00f1oz, A.F., Sivagurunathan, S., Rajwa, B., Carpenter, A.E., Way, G.P. and Singh, S., 2025. A versatile information retrieval framework for evaluating profile strength and similarity. Nature Communications 16, 5181. doi:10.1038/s41467-025-60306-2</p> <p>BibTeX: <pre><code>@article{kalinin2025versatile,\n  author       = {Kalinin, Alexandr A. and Arevalo, John and Serrano, Erik and Vulliard, Loan and Tsang, Hillary and Bornholdt, Michael and Mu\u00f1oz, Al\u00e1n F. and Sivagurunathan, Suganya and Rajwa, Bartek and Carpenter, Anne E. and Way, Gregory P. and Singh, Shantanu},\n  title        = {A versatile information retrieval framework for evaluating profile strength and similarity},\n  journal      = {Nature Communications},\n  year         = {2025},\n  volume       = {16},\n  number       = {1},\n  pages        = {5181},\n  doi          = {10.1038/s41467-025-60306-2},\n  url          = {https://doi.org/10.1038/s41467-025-60306-2},\n  issn         = {2041-1723}\n}\n</code></pre></p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#core-modules","title":"Core Modules","text":"<ul> <li>copairs.matching - Find pairs based on metadata constraints</li> <li>copairs.compute - Calculate similarity metrics</li> <li>copairs.map - Mean Average Precision scoring</li> <li>copairs.replicating - Replication analysis</li> <li>copairs.plot - Visualization utilities</li> </ul>"},{"location":"api/compute/","title":"copairs.compute","text":""},{"location":"api/compute/#copairs.compute","title":"<code>copairs.compute</code>","text":"<p>Functions to compute distances and ranks using numpy operations.</p>"},{"location":"api/compute/#copairs.compute.ap_contiguous","title":"<code>ap_contiguous(rel_k_list, counts)</code>","text":"<p>Compute Average Precision (AP) scores from relevance labels.</p> <p>This function calculates Average Precision (AP) scores for each profile based on relevance labels and their associated counts. It also returns configurations indicating the number of positive and total pairs for each profile.</p> <p>Parameters:</p> <ul> <li> <code>rel_k_list</code>               (<code>ndarray</code>)           \u2013            <p>Array of relevance labels (1 for positive pairs, 0 for negative pairs), sorted by descending similarity within profiles.</p> </li> <li> <code>counts</code>               (<code>ndarray</code>)           \u2013            <p>Array indicating how many times each profile appears in the rank list.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ap_scores</code> (              <code>ndarray</code> )          \u2013            <p>Array of Average Precision scores for each profile.</p> </li> <li> <code>null_confs</code> (              <code>ndarray</code> )          \u2013            <p>Array of configurations, where each row corresponds to: - Number of positive pairs (<code>num_pos</code>). - Total number of pairs (<code>counts</code>).</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def ap_contiguous(\n    rel_k_list: np.ndarray, counts: np.ndarray\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Compute Average Precision (AP) scores from relevance labels.\n\n    This function calculates Average Precision (AP) scores for each profile based on\n    relevance labels and their associated counts. It also returns configurations\n    indicating the number of positive and total pairs for each profile.\n\n    Parameters\n    ----------\n    rel_k_list : np.ndarray\n        Array of relevance labels (1 for positive pairs, 0 for negative pairs), sorted\n        by descending similarity within profiles.\n    counts : np.ndarray\n        Array indicating how many times each profile appears in the rank list.\n\n    Returns\n    -------\n    ap_scores : np.ndarray\n        Array of Average Precision scores for each profile.\n    null_confs : np.ndarray\n        Array of configurations, where each row corresponds to:\n        - Number of positive pairs (`num_pos`).\n        - Total number of pairs (`counts`).\n    \"\"\"\n    # Convert counts into cutoff indices to segment relevance labels\n    cutoffs = to_cutoffs(counts)\n\n    num_pos = np.add.reduceat(rel_k_list, cutoffs, dtype=np.uint32)\n    shift = np.empty_like(num_pos)\n    shift[0], shift[1:] = 0, num_pos[:-1]\n\n    # Calculate cumulative true positives for each profile segment\n    tp = rel_k_list.cumsum() - np.repeat(shift.cumsum(), counts)\n\n    # Rank positions for each relevance label, adjusted by cutoff indices\n    k = np.arange(1, len(rel_k_list) + 1) - np.repeat(cutoffs, counts)\n\n    # Compute precision at each rank (precision = TP / rank)\n    pr_k = tp / k\n\n    # Calculate average precision scores for each profile\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        ap_scores = np.add.reduceat(pr_k * rel_k_list, cutoffs) / num_pos\n\n    # Generate configurations (number of positive and total pairs)\n    null_confs = np.stack([num_pos, counts], axis=1)\n\n    return ap_scores, null_confs\n</code></pre>"},{"location":"api/compute/#copairs.compute.average_precision","title":"<code>average_precision(rel_k)</code>","text":"<p>Compute average precision based on binary list indices.</p> Source code in <code>src/copairs/compute.py</code> <pre><code>def average_precision(rel_k) -&gt; np.ndarray:\n    \"\"\"Compute average precision based on binary list indices.\"\"\"\n    num_pos = rel_k.shape[1]\n    pr_k = np.arange(1, num_pos + 1, dtype=np.float32) / (rel_k + 1)\n    ap_values = pr_k.sum(axis=1) / num_pos\n    return ap_values.astype(np.float32)\n</code></pre>"},{"location":"api/compute/#copairs.compute.batch_processing","title":"<code>batch_processing(pairwise_op, progress_bar=True)</code>","text":"<p>Add batch processing support to pairwise operations.</p> <p>This decorator wraps a pairwise operation to process data in batches, enabling efficient computation and multithreading when working with large datasets.</p> <p>Parameters:</p> <ul> <li> <code>pairwise_op</code>               (<code>Callable</code>)           \u2013            <p>A function that computes pairwise operations (e.g., similarity or distance) between two arrays of features.</p> </li> <li> <code>progress_bar</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether or not to show tqdm's progress bar.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Callable</code>           \u2013            <p>A wrapped function that processes pairwise operations in batches.</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def batch_processing(\n    pairwise_op: Callable[[np.ndarray, np.ndarray], np.ndarray],\n    progress_bar: bool = True,\n):\n    \"\"\"\n    Add batch processing support to pairwise operations.\n\n    This decorator wraps a pairwise operation to process data in batches,\n    enabling efficient computation and multithreading when working with large\n    datasets.\n\n    Parameters\n    ----------\n    pairwise_op : Callable\n        A function that computes pairwise operations (e.g., similarity or distance)\n        between two arrays of features.\n    progress_bar : bool\n        Whether or not to show tqdm's progress bar.\n\n    Returns\n    -------\n    Callable\n        A wrapped function that processes pairwise operations in batches.\n\n    \"\"\"\n\n    def batched_fn(feats: np.ndarray, pair_ix: np.ndarray, batch_size: int):\n        # Total number of pairs to process\n        num_pairs = len(pair_ix)\n\n        # Initialize an empty result array to store pairwise operation results\n        result = np.empty(num_pairs, dtype=np.float32)\n\n        def par_func(i):\n            # Extract the features for the current batch of pairs\n            x_sample = feats[pair_ix[i : i + batch_size, 0]]\n            y_sample = feats[pair_ix[i : i + batch_size, 1]]\n\n            # Compute pairwise operations for the current batch\n            result[i : i + len(x_sample)] = pairwise_op(x_sample, y_sample)\n\n        # Use multithreading to process the batches in parallel\n        parallel_map(\n            par_func, np.arange(0, num_pairs, batch_size), progress_bar=progress_bar\n        )\n\n        return result\n\n    return batched_fn\n</code></pre>"},{"location":"api/compute/#copairs.compute.concat_ranges","title":"<code>concat_ranges(start, end)</code>","text":"<p>Create a 1D array by concatenating multiple integer ranges.</p> <p>This function generates a single concatenated array from multiple ranges defined by the <code>start</code> and <code>end</code> arrays. Each range is inclusive of <code>start</code> and exclusive of <code>end</code>.</p> <p>Parameters:</p> <ul> <li> <code>start</code>               (<code>ndarray</code>)           \u2013            <p>A 1D array of start indices for the ranges.</p> </li> <li> <code>end</code>               (<code>ndarray</code>)           \u2013            <p>A 1D array of end indices for the ranges. Must have the same shape as <code>start</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A 1D array containing the concatenated ranges.</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def concat_ranges(start: np.ndarray, end: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Create a 1D array by concatenating multiple integer ranges.\n\n    This function generates a single concatenated array from multiple ranges defined\n    by the `start` and `end` arrays. Each range is inclusive of `start` and exclusive\n    of `end`.\n\n    Parameters\n    ----------\n    start : np.ndarray\n        A 1D array of start indices for the ranges.\n    end : np.ndarray\n        A 1D array of end indices for the ranges. Must have the same shape as `start`.\n\n    Returns\n    -------\n    np.ndarray\n        A 1D array containing the concatenated ranges.\n    \"\"\"\n    # Generate individual ranges using `range` for each pair of start and end\n    slices = map(range, start, end)\n\n    # Flatten the ranges into a single iterable\n    slices = itertools.chain.from_iterable(slices)\n\n    # Calculate the total length of the concatenated ranges\n    count = (end - start).sum()\n\n    # Create a 1D array from the concatenated ranges\n    mask = np.fromiter(slices, dtype=np.int32, count=count)\n\n    return mask\n</code></pre>"},{"location":"api/compute/#copairs.compute.get_null_dists","title":"<code>get_null_dists(confs, null_size, seed, cache_dir=None, progress_bar=True)</code>","text":"<p>Generate null distributions for each configuration of positive and total pairs.</p> <p>Parameters:</p> <ul> <li> <code>confs</code>               (<code>ndarray</code>)           \u2013            <p>Array where each row contains the number of positive pairs (<code>num_pos</code>) and total pairs (<code>total</code>) for a specific configuration.</p> </li> <li> <code>null_size</code>               (<code>int</code>)           \u2013            <p>Number of samples to generate in the null distribution.</p> </li> <li> <code>seed</code>               (<code>int</code>)           \u2013            <p>Random seed for reproducibility.</p> </li> <li> <code>progress_bar</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether or not to show tqdm's progress bar.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A 2D array where each row corresponds to a null distribution for a specific configuration.</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def get_null_dists(\n    confs: np.ndarray,\n    null_size: int,\n    seed: int,\n    cache_dir: Optional[Union[str, Path]] = None,\n    progress_bar: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"Generate null distributions for each configuration of positive and total pairs.\n\n    Parameters\n    ----------\n    confs : np.ndarray\n        Array where each row contains the number of positive pairs (`num_pos`)\n        and total pairs (`total`) for a specific configuration.\n    null_size : int\n        Number of samples to generate in the null distribution.\n    seed : int\n        Random seed for reproducibility.\n    progress_bar : bool\n        Whether or not to show tqdm's progress bar.\n\n    Returns\n    -------\n    np.ndarray\n        A 2D array where each row corresponds to a null distribution for a specific\n        configuration.\n    \"\"\"\n    # Define the directory for caching null distributions\n    cache_dir = Path.home() / \".copairs\" if cache_dir is None else Path(cache_dir)\n    cache_dir = cache_dir / f\"seed{seed}\" / f\"ns{null_size}\"\n    cache_dir.mkdir(parents=True, exist_ok=True)\n\n    # Number of configurations and random seeds for each configuration\n    num_confs = len(confs)\n    rng = np.random.default_rng(seed)\n    seeds = rng.integers(8096, size=num_confs)\n\n    # Initialize an array to store null distributions\n    null_dists = np.empty([len(confs), null_size], dtype=np.float32)\n\n    # Function to generate null distributions for each configuration\n    def par_func(i):\n        num_pos, total = confs[i]\n        null_dists[i] = null_dist_cached(num_pos, total, seeds[i], null_size, cache_dir)\n\n    # Parallelize the generation of null distributions\n    parallel_map(par_func, np.arange(num_confs), progress_bar)\n\n    return null_dists\n</code></pre>"},{"location":"api/compute/#copairs.compute.get_similarity_fn","title":"<code>get_similarity_fn(distance, progress_bar=True)</code>","text":"<p>Retrieve a similarity function based on a distance string identifier or custom callable.</p> <p>This function provides flexibility in specifying the distance function to be used for pairwise similarity computations. Users can choose a metrics from a predefined set, scipy.spational.distance submodule, or provide a custom callable.</p> <p>Parameters:</p> <ul> <li> <code>distance</code>               (<code>str or callable</code>)           \u2013            <p>The name of the distance function or a custom callable function. Supported string identifiers for predefined metrics are: - \"cosine\": Cosine similarity. - \"abs_cosine\": Absolute cosine similarity. - \"correlation\": Pearson correlation coefficient. - \"euclidean\": Inverse Euclidean distance (scaled to range 0-1). - \"manhattan\": Inverse Manhattan distance (scaled to range 0-1). - \"chebyshev\": Inverse Chebyshev distance (scaled to range 0-1).</p> <p>Additionally, any distance metric supported by <code>scipy.spatial.distance.cdist</code> can be used by providing the metric name as a string.</p> <p>If a callable is provided, it must accept the paramters associated with each callable function.</p> </li> <li> <code>progress_bar</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether or not to show tqdm's progress bar.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>callable</code>           \u2013            <p>A function implementing the specified similarity function.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError:</code>             \u2013            <p>If the provided <code>distance</code> is not a recognized string identifier or a valid callable.</p> </li> </ul> Example: <p>distance_fn = get_distance_fn(\"cosine\") similarity_scores = distance_fn(x_sample, y_sample)</p> Source code in <code>src/copairs/compute.py</code> <pre><code>def get_similarity_fn(\n    distance: Union[str, Callable], progress_bar: bool = True\n) -&gt; Callable:\n    \"\"\"Retrieve a similarity function based on a distance string identifier or custom callable.\n\n    This function provides flexibility in specifying the distance function to be used\n    for pairwise similarity computations. Users can choose a metrics from a predefined set,\n    scipy.spational.distance submodule, or provide a custom callable.\n\n    Parameters\n    ----------\n    distance : str or callable\n        The name of the distance function or a custom callable function. Supported\n        string identifiers for predefined metrics are:\n        - \"cosine\": Cosine similarity.\n        - \"abs_cosine\": Absolute cosine similarity.\n        - \"correlation\": Pearson correlation coefficient.\n        - \"euclidean\": Inverse Euclidean distance (scaled to range 0-1).\n        - \"manhattan\": Inverse Manhattan distance (scaled to range 0-1).\n        - \"chebyshev\": Inverse Chebyshev distance (scaled to range 0-1).\n\n        Additionally, any distance metric supported by `scipy.spatial.distance.cdist`\n        can be used by providing the metric name as a string.\n\n        If a callable is provided, it must accept the paramters associated with each\n        callable function.\n    progress_bar : bool\n        Whether or not to show tqdm's progress bar.\n\n    Returns\n    -------\n    callable\n        A function implementing the specified similarity function.\n\n    Raises\n    ------\n    ValueError:\n        If the provided `distance` is not a recognized string identifier or a valid callable.\n\n    Example:\n    -------\n    &gt;&gt;&gt; distance_fn = get_distance_fn(\"cosine\")\n    &gt;&gt;&gt; similarity_scores = distance_fn(x_sample, y_sample)\n    \"\"\"\n    # Dictionary of supported similarity functions\n    similarity_functions = {\n        \"abs_cosine\": pairwise_abs_cosine,\n        \"cosine\": pairwise_cosine,\n        \"correlation\": pairwise_corr,\n        \"euclidean\": pairwise_euclidean,\n        \"manhattan\": pairwise_manhattan,\n        \"chebyshev\": pairwise_chebyshev,\n    }\n\n    # If a string is provided, look up the corresponding function\n    if isinstance(distance, str):\n        if distance in similarity_functions:\n            similarity_fn = similarity_functions[distance]\n        elif distance in SCIPY_METRICS_NAMES:\n            similarity_fn = lambda x_sample, y_sample: _cdist_diag_sim(\n                x_sample, y_sample, distance\n            )\n        else:\n            raise ValueError(\n                f\"Unsupported distance function: {distance}. Supported functions are: {set(similarity_functions.keys()) | set(SCIPY_METRICS_NAMES)}\"\n            )\n    elif callable(distance):\n        # If a callable is provided, use it directly\n        similarity_fn = distance\n    else:\n        # Raise an error if neither a string nor a callable is provided\n        raise ValueError(\"Distance must be either a string or a callable object.\")\n\n    # Wrap the distance function for efficient batch processing\n    return batch_processing(similarity_fn, progress_bar=progress_bar)\n</code></pre>"},{"location":"api/compute/#copairs.compute.null_dist_cached","title":"<code>null_dist_cached(num_pos, total, seed, null_size, cache_dir)</code>","text":"<p>Generate or retrieve a cached null distribution for a given configuration.</p> <p>This function calculates a null distribution for a specified number of positive pairs (<code>num_pos</code>) and total pairs (<code>total</code>). It uses caching to store and retrieve precomputed distributions, saving time and computational resources.</p> <p>Parameters:</p> <ul> <li> <code>num_pos</code>               (<code>int</code>)           \u2013            <p>Number of positive pairs in the configuration.</p> </li> <li> <code>total</code>               (<code>int</code>)           \u2013            <p>Total number of pairs (positive + negative) in the configuration.</p> </li> <li> <code>seed</code>               (<code>int</code>)           \u2013            <p>Random seed for reproducibility.</p> </li> <li> <code>null_size</code>               (<code>int</code>)           \u2013            <p>Number of samples to generate in the null distribution.</p> </li> <li> <code>cache_dir</code>               (<code>Path</code>)           \u2013            <p>Directory to store or retrieve cached null distributions.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>Null distribution for the specified configuration.</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def null_dist_cached(\n    num_pos: int, total: int, seed: int, null_size: int, cache_dir: Path\n) -&gt; np.ndarray:\n    \"\"\"Generate or retrieve a cached null distribution for a given configuration.\n\n    This function calculates a null distribution for a specified number of positive\n    pairs (`num_pos`) and total pairs (`total`). It uses caching to store and\n    retrieve precomputed distributions, saving time and computational resources.\n\n    Parameters\n    ----------\n    num_pos : int\n        Number of positive pairs in the configuration.\n    total : int\n        Total number of pairs (positive + negative) in the configuration.\n    seed : int\n        Random seed for reproducibility.\n    null_size : int\n        Number of samples to generate in the null distribution.\n    cache_dir : Path\n        Directory to store or retrieve cached null distributions.\n\n    Returns\n    -------\n    np.ndarray\n        Null distribution for the specified configuration.\n    \"\"\"\n    # Check if a seed is provided to enable caching\n    if seed is not None:\n        # Define the cache file name based on the configuration\n        cache_file = cache_dir / f\"n{total}_k{num_pos}.npy\"\n\n        # If the cache file exists, try to load the null distribution from it\n        if cache_file.is_file():\n            try:\n                null_dist = np.load(cache_file)\n            except ValueError as e:\n                # Cache file is corrupted or incomplete, remove it and regenerate\n                warnings.warn(\n                    f\"Failed to load cache file {cache_file}: {e}. Regenerating...\"\n                )\n                cache_file.unlink(missing_ok=True)\n\n                # Compute the null distribution\n                null_dist = random_ap(null_size, num_pos, total, seed)\n\n                # Save the new distribution to the cache\n                np.save(cache_file, null_dist)\n        else:\n            # If the cache file doesn't exist, compute the null distribution\n            null_dist = random_ap(null_size, num_pos, total, seed)\n\n            # Save the computed distribution to the cache\n            np.save(cache_file, null_dist)\n    else:\n        # If no seed is provided, compute the null distribution without caching\n        null_dist = random_ap(null_size, num_pos, total, seed)\n\n    # Return the null distribution (loaded or computed)\n    return null_dist\n</code></pre>"},{"location":"api/compute/#copairs.compute.p_values","title":"<code>p_values(ap_scores, null_confs, null_size, seed, progress_bar=True)</code>","text":"<p>Calculate p-values for an array of Average Precision (AP) scores using a null distribution.</p> <p>Parameters:</p> <ul> <li> <code>ap_scores</code>               (<code>ndarray</code>)           \u2013            <p>Array of observed AP scores for which to calculate p-values.</p> </li> <li> <code>null_confs</code>               (<code>ndarray</code>)           \u2013            <p>Configuration array indicating the relevance or context of each AP score. Used to generate corresponding null distributions.</p> </li> <li> <code>null_size</code>               (<code>int</code>)           \u2013            <p>Number of samples to generate in the null distribution for each configuration.</p> </li> <li> <code>seed</code>               (<code>int</code>)           \u2013            <p>Seed for the random number generator to ensure reproducibility of the null distribution.</p> </li> <li> <code>progress_bar</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether or not to show tqdm's progress bar.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>An array of p-values corresponding to the input AP scores.</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def p_values(\n    ap_scores: np.ndarray,\n    null_confs: np.ndarray,\n    null_size: int,\n    seed: int,\n    progress_bar: bool = True,\n):\n    \"\"\"Calculate p-values for an array of Average Precision (AP) scores using a null distribution.\n\n    Parameters\n    ----------\n    ap_scores : np.ndarray\n        Array of observed AP scores for which to calculate p-values.\n    null_confs : np.ndarray\n        Configuration array indicating the relevance or context of each AP score. Used\n        to generate corresponding null distributions.\n    null_size : int\n        Number of samples to generate in the null distribution for each configuration.\n    seed : int\n        Seed for the random number generator to ensure reproducibility of the null\n        distribution.\n    progress_bar : bool\n        Whether or not to show tqdm's progress bar.\n\n    Returns\n    -------\n    np.ndarray\n        An array of p-values corresponding to the input AP scores.\n    \"\"\"\n    # Identify unique configurations and their indices\n    confs, rev_ix = np.unique(null_confs, axis=0, return_inverse=True)\n\n    # Generate null distributions for each unique configuration\n    null_dists = get_null_dists(confs, null_size, seed, progress_bar=progress_bar)\n\n    # Sort null distributions for efficient p-value computation\n    null_dists.sort(axis=1)\n\n    # Initialize an array to store the p-values\n    pvals = np.empty(len(ap_scores), dtype=np.float32)\n\n    # Compute p-values for each AP score\n    for i, (ap_score, ix) in enumerate(zip(ap_scores, rev_ix)):\n        # Find the rank of the observed AP score in the sorted null distribution\n        num = null_size - np.searchsorted(null_dists[ix], ap_score)\n\n        # Calculate the p-value as the proportion of null scores &gt;= observed score\n        pvals[i] = (num + 1) / (null_size + 1)\n\n    return pvals\n</code></pre>"},{"location":"api/compute/#copairs.compute.pairwise_abs_cosine","title":"<code>pairwise_abs_cosine(x_sample, y_sample)</code>","text":"<p>Compute the absolute cosine similarity for paired rows of two matrices.</p> <p>Parameters:</p> <ul> <li> <code>x_sample</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array where each row represents a profile.</p> </li> <li> <code>y_sample</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array of the same shape as <code>x_sample</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>Absolute values of cosine similarity scores.</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def pairwise_abs_cosine(x_sample: np.ndarray, y_sample: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute the absolute cosine similarity for paired rows of two matrices.\n\n    Parameters\n    ----------\n    x_sample : np.ndarray\n        A 2D array where each row represents a profile.\n    y_sample : np.ndarray\n        A 2D array of the same shape as `x_sample`.\n\n    Returns\n    -------\n    np.ndarray\n        Absolute values of cosine similarity scores.\n    \"\"\"\n    return np.abs(pairwise_cosine(x_sample, y_sample))\n</code></pre>"},{"location":"api/compute/#copairs.compute.pairwise_chebyshev","title":"<code>pairwise_chebyshev(x_sample, y_sample)</code>","text":"<p>Compute the inverse Chebyshev distance for paired rows of two matrices.</p> <p>Parameters:</p> <ul> <li> <code>x_sample</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array where each row represents a profile.</p> </li> <li> <code>y_sample</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array of the same shape as <code>x_sample</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A 1D array of inverse Chebyshev distance scores (scaled to range 0-1).</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def pairwise_chebyshev(x_sample: np.ndarray, y_sample: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute the inverse Chebyshev distance for paired rows of two matrices.\n\n    Parameters\n    ----------\n    x_sample : np.ndarray\n        A 2D array where each row represents a profile.\n    y_sample : np.ndarray\n        A 2D array of the same shape as `x_sample`.\n\n    Returns\n    -------\n    np.ndarray\n        A 1D array of inverse Chebyshev distance scores (scaled to range 0-1).\n    \"\"\"\n    c_dist = np.max(np.abs(x_sample - y_sample), axis=1)\n    return 1 / (1 + c_dist)\n</code></pre>"},{"location":"api/compute/#copairs.compute.pairwise_corr","title":"<code>pairwise_corr(x_sample, y_sample)</code>","text":"<p>Compute the Pearson correlation coefficient for paired rows of two matrices.</p> <p>Parameters:</p> <ul> <li> <code>x_sample</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array where each row represents a profile</p> </li> <li> <code>y_sample</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array of the same shape as <code>x_sample</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A 1D array of Pearson correlation coefficients for each row pair in <code>x_sample</code> and <code>y_sample</code>.</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def pairwise_corr(x_sample: np.ndarray, y_sample: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute the Pearson correlation coefficient for paired rows of two matrices.\n\n    Parameters\n    ----------\n    x_sample : np.ndarray\n        A 2D array where each row represents a profile\n    y_sample : np.ndarray\n        A 2D array of the same shape as `x_sample`.\n\n    Returns\n    -------\n    np.ndarray\n        A 1D array of Pearson correlation coefficients for each row pair in\n        `x_sample` and `y_sample`.\n    \"\"\"\n    # Compute the mean for each row\n    x_mean = x_sample.mean(axis=1, keepdims=True)\n    y_mean = y_sample.mean(axis=1, keepdims=True)\n\n    # Center the rows by subtracting the mean\n    x_center = x_sample - x_mean\n    y_center = y_sample - y_mean\n\n    # Compute the numerator (dot product of centered vectors)\n    numer = (x_center * y_center).sum(axis=1)\n\n    # Compute the denominator (product of vector magnitudes)\n    denom = (x_center**2).sum(axis=1) * (y_center**2).sum(axis=1)\n    denom = np.sqrt(denom)\n\n    # Calculate correlation coefficients\n    corrs = numer / denom\n    return corrs\n</code></pre>"},{"location":"api/compute/#copairs.compute.pairwise_cosine","title":"<code>pairwise_cosine(x_sample, y_sample)</code>","text":"<p>Compute cosine similarity for paired rows of two matrices.</p> <p>Parameters:</p> <ul> <li> <code>x_sample</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array where each row represents a profile.</p> </li> <li> <code>y_sample</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array of the same shape as <code>x_sample</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A 1D array of cosine similarity scores for each row pair in <code>x_sample</code> and <code>y_sample</code>.</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def pairwise_cosine(x_sample: np.ndarray, y_sample: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute cosine similarity for paired rows of two matrices.\n\n    Parameters\n    ----------\n    x_sample : np.ndarray\n        A 2D array where each row represents a profile.\n    y_sample : np.ndarray\n        A 2D array of the same shape as `x_sample`.\n\n    Returns\n    -------\n    np.ndarray\n        A 1D array of cosine similarity scores for each row pair in `x_sample` and `y_sample`.\n    \"\"\"\n    # Normalize each row to unit vectors\n    x_norm = x_sample / np.linalg.norm(x_sample, axis=1)[:, np.newaxis]\n    y_norm = y_sample / np.linalg.norm(y_sample, axis=1)[:, np.newaxis]\n\n    # Compute the dot product of normalized vectors\n    c_sim = np.sum(x_norm * y_norm, axis=1)\n    return c_sim\n</code></pre>"},{"location":"api/compute/#copairs.compute.pairwise_euclidean","title":"<code>pairwise_euclidean(x_sample, y_sample)</code>","text":"<p>Compute the inverse Euclidean distance for paired rows of two matrices.</p> <p>Parameters:</p> <ul> <li> <code>x_sample</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array where each row represents a profile.</p> </li> <li> <code>y_sample</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array of the same shape as <code>x_sample</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A 1D array of inverse Euclidean distance scores (scaled to range 0-1).</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def pairwise_euclidean(x_sample: np.ndarray, y_sample: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Compute the inverse Euclidean distance for paired rows of two matrices.\n\n    Parameters\n    ----------\n    x_sample : np.ndarray\n        A 2D array where each row represents a profile.\n    y_sample : np.ndarray\n        A 2D array of the same shape as `x_sample`.\n\n    Returns\n    -------\n    np.ndarray\n        A 1D array of inverse Euclidean distance scores (scaled to range 0-1).\n    \"\"\"\n    # Compute Euclidean distance and scale to a range of 0 to 1\n    e_dist = np.sqrt(np.sum((x_sample - y_sample) ** 2, axis=1))\n    return 1 / (1 + e_dist)\n</code></pre>"},{"location":"api/compute/#copairs.compute.pairwise_manhattan","title":"<code>pairwise_manhattan(x_sample, y_sample)</code>","text":"<p>Compute the inverse Manhattan distance for paired rows of two matrices.</p> <p>Parameters:</p> <ul> <li> <code>x_sample</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array where each row represents a profile.</p> </li> <li> <code>y_sample</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array of the same shape as <code>x_sample</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A 1D array of inverse Manhattan distance scores (scaled to range 0-1).</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def pairwise_manhattan(x_sample: np.ndarray, y_sample: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Compute the inverse Manhattan distance for paired rows of two matrices.\n\n    Parameters\n    ----------\n    x_sample : np.ndarray\n        A 2D array where each row represents a profile.\n    y_sample : np.ndarray\n        A 2D array of the same shape as `x_sample`.\n\n    Returns\n    -------\n    np.ndarray\n        A 1D array of inverse Manhattan distance scores (scaled to range 0-1).\n    \"\"\"\n    m_dist = np.sum(np.abs(x_sample - y_sample), axis=1)\n    return 1 / (1 + m_dist)\n</code></pre>"},{"location":"api/compute/#copairs.compute.parallel_map","title":"<code>parallel_map(par_func, items, progress_bar=True)</code>","text":"<p>Execute a function in parallel over a list of items.</p> <p>This function uses a thread pool to process items in parallel, with progress tracking via <code>tqdm</code>. It is particularly useful for batch operations that benefit from multithreading.</p> <p>Parameters:</p> <ul> <li> <code>par_func</code>               (<code>Callable</code>)           \u2013            <p>A function to execute for each item. It should accept a single argument (an item index or value).</p> </li> <li> <code>items</code>               (<code>ndarray</code>)           \u2013            <p>An array or list of items to process.</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def parallel_map(\n    par_func: Callable[[int], None],\n    items: np.ndarray,\n    progress_bar: bool = True,\n) -&gt; None:\n    \"\"\"Execute a function in parallel over a list of items.\n\n    This function uses a thread pool to process items in parallel, with progress\n    tracking via `tqdm`. It is particularly useful for batch operations that benefit\n    from multithreading.\n\n    Parameters\n    ----------\n    par_func : Callable\n        A function to execute for each item. It should accept a single argument\n        (an item index or value).\n    items : np.ndarray\n        An array or list of items to process.\n    \"\"\"\n    # Total number of items to process\n    num_items = len(items)\n\n    # Determine the number of threads to use, limited by CPU count\n    pool_size = min(num_items, os.cpu_count())\n\n    # Calculate chunk size for dividing work among threads\n    chunksize = num_items // pool_size\n\n    # Use a thread pool to execute the function in parallel\n    with ThreadPool(pool_size) as pool:\n        # Map the function to items with unordered execution for better efficiency\n        tasks = pool.imap_unordered(par_func, items, chunksize=chunksize)\n\n        if progress_bar:\n            # Display progress using tqdm\n            from tqdm.autonotebook import tqdm\n\n            tasks = tqdm(tasks, total=len(items), leave=False)\n        for _ in tasks:\n            pass\n</code></pre>"},{"location":"api/compute/#copairs.compute.random_ap","title":"<code>random_ap(num_perm, num_pos, total, seed)</code>","text":"<p>Generate random Average Precision (AP) scores to create a null distribution.</p> <p>This function computes multiple Average Precision (AP) scores based on randomly generated binary relevance lists. It is useful for generating a null distribution to assess the significance of observed AP scores.</p> <p>Parameters:</p> <ul> <li> <code>num_perm</code>               (<code>int</code>)           \u2013            <p>Number of random permutations (i.e., how many random relevance lists to generate).</p> </li> <li> <code>num_pos</code>               (<code>int</code>)           \u2013            <p>Number of positive samples (1's) in each relevance list.</p> </li> <li> <code>total</code>               (<code>int</code>)           \u2013            <p>Total number of samples (columns) in each relevance list.</p> </li> <li> <code>seed</code>               (<code>int</code>)           \u2013            <p>Seed for the random number generator to ensure reproducibility.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A 1D array containing the Average Precision scores for each randomly generated relevance list.</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def random_ap(num_perm: int, num_pos: int, total: int, seed: int):\n    \"\"\"Generate random Average Precision (AP) scores to create a null distribution.\n\n    This function computes multiple Average Precision (AP) scores based on randomly\n    generated binary relevance lists. It is useful for generating a null distribution\n    to assess the significance of observed AP scores.\n\n    Parameters\n    ----------\n    num_perm : int\n        Number of random permutations (i.e., how many random relevance lists to generate).\n    num_pos : int\n        Number of positive samples (1's) in each relevance list.\n    total : int\n        Total number of samples (columns) in each relevance list.\n    seed : int\n        Seed for the random number generator to ensure reproducibility.\n\n    Returns\n    -------\n    np.ndarray\n        A 1D array containing the Average Precision scores for each randomly\n        generated relevance list.\n    \"\"\"\n    # Initialize the random number generator\n    rng = np.random.default_rng(seed)\n\n    # Generate a binary matrix with `num_perm` rows and `total` columns,\n    # where each row contains exactly `num_pos` ones distributed randomly\n    rel_k = random_binary_matrix(num_perm, total, num_pos, rng)\n\n    # Compute Average Precision (AP) scores for each row of the binary matrix\n    null_dist = average_precision(rel_k)\n    return null_dist\n</code></pre>"},{"location":"api/compute/#copairs.compute.random_binary_matrix","title":"<code>random_binary_matrix(n, m, k, rng)</code>","text":"<p>Generate a indices of k values in 1 per row in a random binary n*m matrix.</p> <p>Args: n: Number of rows. m: Number of columns. k: Number of 1's per row.</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A binary matrix of shape <code>(n, m)</code> with exactly <code>k</code> ones per row.</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def random_binary_matrix(n, m, k, rng):\n    \"\"\"Generate a indices of k values in 1 per row in a random binary n*m matrix.\n\n    Args:\n    n: Number of rows.\n    m: Number of columns.\n    k: Number of 1's per row.\n\n    Returns\n    -------\n    np.ndarray\n        A binary matrix of shape `(n, m)` with exactly `k` ones per row.\n    \"\"\"\n    dtype = np.uint16 if m &lt; 2**16 else np.uint32\n    indices = np.tile(np.arange(m, dtype=dtype), (n, 1))\n    rng.permuted(indices, axis=1, out=indices)\n    return np.sort(indices[:, :k], axis=1)\n</code></pre>"},{"location":"api/compute/#copairs.compute.to_cutoffs","title":"<code>to_cutoffs(counts)</code>","text":"<p>Convert counts into cumulative cutoff indices.</p> <p>This function generates a 1D array of indices that mark the start of each segment in a cumulative list. The first index is always <code>0</code>, and subsequent indices correspond to the cumulative sum of counts up to the previous entry.</p> <p>Parameters:</p> <ul> <li> <code>counts</code>               (<code>ndarray</code>)           \u2013            <p>A 1D array of counts representing the size of each segment.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A 1D array of cutoff indices where each value indicates the starting index for the corresponding segment.</p> </li> </ul> Source code in <code>src/copairs/compute.py</code> <pre><code>def to_cutoffs(counts: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Convert counts into cumulative cutoff indices.\n\n    This function generates a 1D array of indices that mark the start of each segment\n    in a cumulative list. The first index is always `0`, and subsequent indices\n    correspond to the cumulative sum of counts up to the previous entry.\n\n    Parameters\n    ----------\n    counts : np.ndarray\n        A 1D array of counts representing the size of each segment.\n\n    Returns\n    -------\n    np.ndarray\n        A 1D array of cutoff indices where each value indicates the starting index\n        for the corresponding segment.\n    \"\"\"\n    # Initialize an empty array for cutoff indices\n    cutoffs = np.empty_like(counts)\n\n    # Set the first cutoff to 0 (start of the first segment)\n    cutoffs[0] = 0\n\n    # Compute subsequent cutoffs using cumulative sums, excluding the last element\n    cutoffs[1:] = counts.cumsum()[:-1]\n\n    return cutoffs\n</code></pre>"},{"location":"api/map/","title":"copairs.map","text":""},{"location":"api/map/#copairs.map","title":"<code>copairs.map</code>","text":"<p>Module to compute mAP-based metrics.</p>"},{"location":"api/map/#copairs.map.mean_average_precision","title":"<code>mean_average_precision(ap_scores, sameby, null_size, threshold, seed, progress_bar=True, max_workers=None, cache_dir=None)</code>","text":"<p>Calculate the Mean Average Precision (mAP) score and associated p-values.</p> <p>This function computes the Mean Average Precision (mAP) score by grouping profiles based on the specified criteria (<code>sameby</code>). It calculates the significance of mAP scores by comparing them to a null distribution and performs multiple testing corrections.</p> <p>Parameters:</p> <ul> <li> <code>ap_scores</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing individual Average Precision (AP) scores and pair statistics (e.g., number of positive pairs <code>n_pos_pairs</code> and total pairs <code>n_total_pairs</code>).</p> </li> <li> <code>sameby</code>               (<code>list or str</code>)           \u2013            <p>Metadata column(s) used to group profiles for mAP calculation.</p> </li> <li> <code>null_size</code>               (<code>int</code>)           \u2013            <p>Number of samples in the null distribution for significance testing.</p> </li> <li> <code>threshold</code>               (<code>float</code>)           \u2013            <p>p-value threshold for identifying significant MaP scores.</p> </li> <li> <code>seed</code>               (<code>int</code>)           \u2013            <p>Random seed for reproducibility.</p> </li> <li> <code>progress_bar</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether or not to show tqdm's progress bar.</p> </li> <li> <code>max_workers</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Number of workers used. Default defined by tqdm's <code>thread_map</code>.</p> </li> <li> <code>cache_dir</code>               (<code>str or Path</code>, default:                   <code>None</code> )           \u2013            <p>Location to save the cache.</p> </li> <li> <code>progress_bar</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether or not to show tqdm's progress bar.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>DataFrame with the following columns: - <code>mean_average_precision</code>: Mean AP score for each group. - <code>p_value</code>: p-value comparing mAP to the null distribution. - <code>corrected_p_value</code>: Adjusted p-value after multiple testing correction. - <code>below_p</code>: Boolean indicating if the p-value is below the threshold. - <code>below_corrected_p</code>: Boolean indicating if the corrected p-value is below the threshold.</p> </li> </ul> Source code in <code>src/copairs/map/map.py</code> <pre><code>def mean_average_precision(\n    ap_scores: pd.DataFrame,\n    sameby: List[str],\n    null_size: int,\n    threshold: float,\n    seed: int,\n    progress_bar: bool = True,\n    max_workers: Optional[int] = None,\n    cache_dir: Optional[Union[str, Path]] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Calculate the Mean Average Precision (mAP) score and associated p-values.\n\n    This function computes the Mean Average Precision (mAP) score by grouping profiles\n    based on the specified criteria (`sameby`). It calculates the significance of mAP\n    scores by comparing them to a null distribution and performs multiple testing\n    corrections.\n\n    Parameters\n    ----------\n    ap_scores : pd.DataFrame\n        DataFrame containing individual Average Precision (AP) scores and pair statistics\n        (e.g., number of positive pairs `n_pos_pairs` and total pairs `n_total_pairs`).\n    sameby : list or str\n        Metadata column(s) used to group profiles for mAP calculation.\n    null_size : int\n        Number of samples in the null distribution for significance testing.\n    threshold : float\n        p-value threshold for identifying significant MaP scores.\n    seed : int\n        Random seed for reproducibility.\n    progress_bar : bool\n        Whether or not to show tqdm's progress bar.\n    max_workers : int\n        Number of workers used. Default defined by tqdm's `thread_map`.\n    cache_dir : str or Path\n        Location to save the cache.\n    progress_bar : bool\n        Whether or not to show tqdm's progress bar.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with the following columns:\n        - `mean_average_precision`: Mean AP score for each group.\n        - `p_value`: p-value comparing mAP to the null distribution.\n        - `corrected_p_value`: Adjusted p-value after multiple testing correction.\n        - `below_p`: Boolean indicating if the p-value is below the threshold.\n        - `below_corrected_p`: Boolean indicating if the corrected p-value is below the threshold.\n    \"\"\"\n    # Filter out invalid or incomplete AP scores\n    ap_scores = ap_scores.query(\"~average_precision.isna() and n_pos_pairs &gt; 0\")\n    ap_scores = ap_scores.reset_index(drop=True).copy()\n\n    logger.info(\"Computing null_dist...\")\n    # Extract configurations for null distribution generation\n    null_confs = ap_scores[[\"n_pos_pairs\", \"n_total_pairs\"]].values\n    null_confs, rev_ix = np.unique(null_confs, axis=0, return_inverse=True)\n\n    # Generate null distributions for each unique configuration\n    null_dists = compute.get_null_dists(\n        null_confs, null_size, seed=seed, cache_dir=cache_dir, progress_bar=progress_bar\n    )\n    ap_scores[\"null_ix\"] = rev_ix\n\n    # Function to calculate the p-value for a mAP score based on the null distribution\n    def get_p_value(params):\n        map_score, indices = params\n        null_dist = null_dists[rev_ix[indices]].mean(axis=0)\n        num = (null_dist &gt; map_score).sum()\n        p_value = (num + 1) / (null_size + 1)  # Add 1 for stability\n        return p_value\n\n    logger.info(\"Computing p-values...\")\n\n    # Group by the specified metadata column(s) and calculate mean AP\n    map_scores = ap_scores.groupby(sameby, observed=True, as_index=False).agg(\n        {\n            \"average_precision\": [\"mean\", lambda x: list(x.index)],\n        }\n    )\n    map_scores.columns = sameby + [\"mean_average_precision\", \"indices\"]\n\n    # Compute p-values for each group using the null distributions\n    params = map_scores[[\"mean_average_precision\", \"indices\"]]\n\n    if progress_bar:\n        from tqdm.contrib.concurrent import thread_map\n    else:\n        thread_map = silent_thread_map\n\n    map_scores[\"p_value\"] = thread_map(\n        get_p_value, params.values, leave=False, max_workers=max_workers\n    )\n\n    # Perform multiple testing correction on p-values\n    reject, pvals_corrected, alphacSidak, alphacBonf = multipletests(\n        map_scores[\"p_value\"], method=\"fdr_bh\"\n    )\n    map_scores[\"corrected_p_value\"] = pvals_corrected\n\n    # Mark scores below the p-value threshold\n    map_scores[\"below_p\"] = map_scores[\"p_value\"] &lt; threshold\n    map_scores[\"below_corrected_p\"] = map_scores[\"corrected_p_value\"] &lt; threshold\n\n    return map_scores\n</code></pre>"},{"location":"api/map/#copairs.map.average_precision","title":"<code>average_precision</code>","text":"<p>Functions to compute average precision.</p>"},{"location":"api/map/#copairs.map.average_precision.average_precision","title":"<code>average_precision(meta, feats, pos_sameby, pos_diffby, neg_sameby, neg_diffby, batch_size=20000, distance='cosine', progress_bar=True)</code>","text":"<p>Calculate average precision (AP) scores for pairs of profiles based on their similarity.</p> <p>This function identifies positive and negative pairs of profiles using  metadata rules, computes their similarity scores, and calculates average precision scores for each profile. The results include the number of positive and total pairs for each profile.</p> <p>Parameters:</p> <ul> <li> <code>meta</code>               (<code>DataFrame</code>)           \u2013            <p>Metadata of the profiles, including columns used for defining pairs. This DataFrame should include the columns specified in <code>pos_sameby</code>, <code>pos_diffby</code>, <code>neg_sameby</code>, and <code>neg_diffby</code>.</p> </li> <li> <code>feats</code>               (<code>ndarray</code>)           \u2013            <p>Feature matrix representing the profiles, where rows correspond to profiles and columns to features.</p> </li> <li> <code>pos_sameby</code>               (<code>list</code>)           \u2013            <p>Metadata columns used to define positive pairs. Two profiles are considered a positive pair if they belong to the same group that is not a control group. For example, replicate profiles of the same compound are positive pairs and should share the same value in a column identifying compounds.</p> </li> <li> <code>pos_diffby</code>               (<code>list</code>)           \u2013            <p>Metadata columns used to differentiate positive pairs. Positive pairs do not need to differ in any metadata columns, so this is typically left empty. However, if necessary (e.g., to account for batch effects), you can specify columns such as batch identifiers.</p> </li> <li> <code>neg_sameby</code>               (<code>list</code>)           \u2013            <p>Metadata columns used to define negative pairs. Typically left empty, as profiles forming a negative pair (e.g., a compound and a DMSO/control) do not need to share any metadata values. This ensures comparisons are made without enforcing unnecessary constraints.</p> </li> <li> <code>neg_diffby</code>               (<code>list</code>)           \u2013            <p>Metadata columns used to differentiate negative pairs. Two profiles are considered a negative pair if one belongs to a compound group and the other to a DMSO/ control group. They must differ in specified metadata columns, such as those identifying the compound and the treatment index, to ensure comparisons are only made between compounds and DMSO controls (not between different compounds).</p> </li> <li> <code>batch_size</code>               (<code>int</code>, default:                   <code>20000</code> )           \u2013            <p>The batch size for similarity computations to optimize memory usage. Default is 20000.</p> </li> <li> <code>distance</code>               (<code>str</code>, default:                   <code>'cosine'</code> )           \u2013            <p>The distance function used for computing similarities. Default is \"cosine\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>A DataFrame containing the following columns: - 'average_precision': The calculated average precision score for each profile. - 'n_pos_pairs': The number of positive pairs for each profile. - 'n_total_pairs': The total number of pairs for each profile. - Additional metadata columns from the input.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>UnpairedException</code>             \u2013            <p>If no positive or negative pairs are found in the dataset.</p> </li> </ul> Notes <ul> <li>Positive Pair Rules:<ul> <li>Positive pairs are defined by <code>pos_sameby</code> (profiles share these metadata values)   and optionally differentiated by <code>pos_diffby</code> (profiles must differ in these metadata values if specified).</li> </ul> </li> <li>Negative Pair Rules:<ul> <li>Negative pairs are defined by <code>neg_diffby</code> (profiles differ in these metadata values)   and optionally constrained by <code>neg_sameby</code> (profiles share these metadata values if specified).</li> </ul> </li> </ul> Source code in <code>src/copairs/map/average_precision.py</code> <pre><code>def average_precision(\n    meta: pd.DataFrame,\n    feats: pd.DataFrame,\n    pos_sameby: List[str],\n    pos_diffby: List[str],\n    neg_sameby: List[str],\n    neg_diffby: List[str],\n    batch_size: int = 20000,\n    distance: str = \"cosine\",\n    progress_bar: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"Calculate average precision (AP) scores for pairs of profiles based on their similarity.\n\n    This function identifies positive and negative pairs of profiles using  metadata\n    rules, computes their similarity scores, and calculates average precision\n    scores for each profile. The results include the number of positive and total pairs\n    for each profile.\n\n    Parameters\n    ----------\n    meta : pd.DataFrame\n        Metadata of the profiles, including columns used for defining pairs.\n        This DataFrame should include the columns specified in `pos_sameby`,\n        `pos_diffby`, `neg_sameby`, and `neg_diffby`.\n\n    feats : np.ndarray\n        Feature matrix representing the profiles, where rows correspond to profiles\n        and columns to features.\n\n    pos_sameby : list\n        Metadata columns used to define positive pairs. Two profiles are considered a\n        positive pair if they belong to the same group that is not a control group.\n        For example, replicate profiles of the same compound are positive pairs and\n        should share the same value in a column identifying compounds.\n\n    pos_diffby : list\n        Metadata columns used to differentiate positive pairs. Positive pairs do not need\n        to differ in any metadata columns, so this is typically left empty. However,\n        if necessary (e.g., to account for batch effects), you can specify columns\n        such as batch identifiers.\n\n    neg_sameby : list\n        Metadata columns used to define negative pairs. Typically left empty, as profiles\n        forming a negative pair (e.g., a compound and a DMSO/control) do not need to\n        share any metadata values. This ensures comparisons are made without enforcing\n        unnecessary constraints.\n\n    neg_diffby : list\n        Metadata columns used to differentiate negative pairs. Two profiles are considered\n        a negative pair if one belongs to a compound group and the other to a DMSO/\n        control group. They must differ in specified metadata columns, such as those\n        identifying the compound and the treatment index, to ensure comparisons are\n        only made between compounds and DMSO controls (not between different compounds).\n\n    batch_size : int\n        The batch size for similarity computations to optimize memory usage.\n        Default is 20000.\n\n    distance : str\n        The distance function used for computing similarities. Default is \"cosine\".\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame containing the following columns:\n        - 'average_precision': The calculated average precision score for each profile.\n        - 'n_pos_pairs': The number of positive pairs for each profile.\n        - 'n_total_pairs': The total number of pairs for each profile.\n        - Additional metadata columns from the input.\n\n    Raises\n    ------\n    UnpairedException\n        If no positive or negative pairs are found in the dataset.\n\n    Notes\n    -----\n    - Positive Pair Rules:\n        * Positive pairs are defined by `pos_sameby` (profiles share these metadata values)\n          and optionally differentiated by `pos_diffby` (profiles must differ in these metadata values if specified).\n    - Negative Pair Rules:\n        * Negative pairs are defined by `neg_diffby` (profiles differ in these metadata values)\n          and optionally constrained by `neg_sameby` (profiles share these metadata values if specified).\n    \"\"\"\n    # Combine all metadata columns needed for pair definitions\n    columns = flatten_str_list(pos_sameby, pos_diffby, neg_sameby, neg_diffby)\n\n    # Validate and filter metadata to ensure the required columns are present and usable\n    meta, columns = evaluate_and_filter(meta, columns)\n    validate_pipeline_input(meta, feats, columns)\n\n    # Get the distance function for similarity calculations (e.g., cosine)\n    similarity_fn = compute.get_similarity_fn(distance, progress_bar=progress_bar)\n\n    # Reset metadata index for consistent indexing\n    meta = meta.reset_index(drop=True).copy()\n\n    logger.info(\"Indexing metadata...\")\n\n    # Identify positive pairs based on `pos_sameby` and `pos_diffby`\n    logger.info(\"Finding positive pairs...\")\n    pos_pairs = find_pairs(meta, sameby=pos_sameby, diffby=pos_diffby)\n    if len(pos_pairs) == 0:\n        raise UnpairedException(\"Unable to find positive pairs.\")\n\n    # Identify negative pairs based on `neg_sameby` and `neg_diffby`\n    logger.info(\"Finding negative pairs...\")\n    neg_pairs = find_pairs(meta, sameby=neg_sameby, diffby=neg_diffby)\n    if len(neg_pairs) == 0:\n        raise UnpairedException(\"Unable to find negative pairs.\")\n\n    # Compute similarities for positive pairs\n    logger.info(\"Computing positive similarities...\")\n    pos_sims = similarity_fn(feats, pos_pairs, batch_size)\n\n    # Compute similarities for negative pairs\n    logger.info(\"Computing negative similarities...\")\n    neg_sims = similarity_fn(feats, neg_pairs, batch_size)\n\n    # Build rank lists for calculating average precision\n    logger.info(\"Building rank lists...\")\n    paired_ix, rel_k_list, counts = build_rank_lists(\n        pos_pairs, neg_pairs, pos_sims, neg_sims\n    )\n\n    # Compute average precision scores and associated configurations\n    logger.info(\"Computing average precision...\")\n    ap_scores, null_confs = compute.ap_contiguous(rel_k_list, counts)\n\n    # Add AP scores and pair counts to the metadata DataFrame\n    logger.info(\"Creating result DataFrame...\")\n    meta[\"n_pos_pairs\"] = 0\n    meta[\"n_total_pairs\"] = 0\n    meta.loc[paired_ix, \"average_precision\"] = ap_scores\n    meta.loc[paired_ix, \"n_pos_pairs\"] = null_confs[:, 0]\n    meta.loc[paired_ix, \"n_total_pairs\"] = null_confs[:, 1]\n\n    logger.info(\"Finished.\")\n    return meta\n</code></pre>"},{"location":"api/map/#copairs.map.average_precision.build_rank_lists","title":"<code>build_rank_lists(pos_pairs, neg_pairs, pos_sims, neg_sims)</code>","text":"<p>Build rank lists for calculating average precision.</p> <p>This function processes positive and negative pairs along with their similarity scores to construct rank lists and determine unique profile indices with their associated counts.</p> <p>Parameters:</p> <ul> <li> <code>pos_pairs</code>               (<code>ndarray</code>)           \u2013            <p>Array of positive pair indices, where each pair is represented as a pair of integers.</p> </li> <li> <code>neg_pairs</code>               (<code>ndarray</code>)           \u2013            <p>Array of negative pair indices, where each pair is represented as a pair of integers.</p> </li> <li> <code>pos_sims</code>               (<code>ndarray</code>)           \u2013            <p>Array of similarity scores for positive pairs.</p> </li> <li> <code>neg_sims</code>               (<code>ndarray</code>)           \u2013            <p>Array of similarity scores for negative pairs.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>paired_ix</code> (              <code>ndarray</code> )          \u2013            <p>Unique indices of profiles that appear in the rank lists.</p> </li> <li> <code>rel_k_list</code> (              <code>ndarray</code> )          \u2013            <p>Array of relevance labels (1 for positive pairs, 0 for negative pairs) sorted by decreasing similarity within each profile.</p> </li> <li> <code>counts</code> (              <code>ndarray</code> )          \u2013            <p>Array of counts indicating how many times each profile index appears in the rank lists.</p> </li> </ul> Source code in <code>src/copairs/map/average_precision.py</code> <pre><code>def build_rank_lists(\n    pos_pairs: np.ndarray,\n    neg_pairs: np.ndarray,\n    pos_sims: np.ndarray,\n    neg_sims: np.ndarray,\n):\n    \"\"\"Build rank lists for calculating average precision.\n\n    This function processes positive and negative pairs along with their similarity scores\n    to construct rank lists and determine unique profile indices with their associated counts.\n\n    Parameters\n    ----------\n    pos_pairs : np.ndarray\n        Array of positive pair indices, where each pair is represented as a pair of integers.\n\n    neg_pairs : np.ndarray\n        Array of negative pair indices, where each pair is represented as a pair of integers.\n\n    pos_sims : np.ndarray\n        Array of similarity scores for positive pairs.\n\n    neg_sims : np.ndarray\n        Array of similarity scores for negative pairs.\n\n    Returns\n    -------\n    paired_ix : np.ndarray\n        Unique indices of profiles that appear in the rank lists.\n\n    rel_k_list : np.ndarray\n        Array of relevance labels (1 for positive pairs, 0 for negative pairs) sorted by\n        decreasing similarity within each profile.\n\n    counts : np.ndarray\n        Array of counts indicating how many times each profile index appears in the rank lists.\n    \"\"\"\n    # Combine relevance labels: 1 for positive pairs, 0 for negative pairs\n    labels = np.concatenate(\n        [\n            np.ones(pos_pairs.size, dtype=np.uint32),\n            np.zeros(neg_pairs.size, dtype=np.uint32),\n        ]\n    )\n\n    # Flatten positive and negative pair indices for ranking\n    ix = np.concatenate([pos_pairs.ravel(), neg_pairs.ravel()])\n\n    # Expand similarity scores to match the flattened pair indices\n    sim_all = np.concatenate([np.repeat(pos_sims, 2), np.repeat(neg_sims, 2)])\n\n    # Sort by index (lexicographical order) and then by similarity (descending)\n    # `1 - sim_all` ensures higher similarity values appear first, prioritizing\n    # pairs with stronger similarity scores for ranking.\n    # `ix` acts as a secondary criterion, ensuring consistent ordering of pairs\n    # with equal similarity scores by their indices (lexicographical order).\n    ix_sort = np.lexsort([1 - sim_all, ix])\n\n    # Create the rank list of relevance labels sorted by similarity and index\n    rel_k_list = labels[ix_sort]\n\n    # Find unique profile indices and count their occurrences in the pairs\n    paired_ix, counts = np.unique(ix, return_counts=True)\n\n    return paired_ix, rel_k_list, counts.astype(np.uint32)\n</code></pre>"},{"location":"api/map/#copairs.map.average_precision.p_values","title":"<code>p_values(dframe, null_size, seed, progress_bar=True)</code>","text":"<p>Compute p-values for average precision scores based on a null distribution.</p> <p>This function calculates the p-values for each profile in the input DataFrame, comparing their average precision scores (<code>average_precision</code>) against a null distribution generated for their specific configurations (number of positive and total pairs). Profiles with no positive pairs are excluded from the p-value calculation.</p> <p>Parameters:</p> <ul> <li> <code>dframe</code>               (<code>DataFrame</code>)           \u2013            <p>A DataFrame containing the following columns: - <code>average_precision</code>: The AP scores for each profile. - <code>n_pos_pairs</code>: Number of positive pairs for each profile. - <code>n_total_pairs</code>: Total number of pairs (positive + negative) for each profile.</p> </li> <li> <code>null_size</code>               (<code>int</code>)           \u2013            <p>The number of samples to generate in the null distribution for significance testing.</p> </li> <li> <code>seed</code>               (<code>int</code>)           \u2013            <p>Random seed for reproducibility of the null distribution.</p> </li> <li> <code>progress_bar</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether or not to show tqdm's progress bar.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>An array of p-values for each profile in the DataFrame. Profiles with no positive pairs will have NaN as their p-value.</p> </li> </ul> Source code in <code>src/copairs/map/average_precision.py</code> <pre><code>def p_values(\n    dframe: pd.DataFrame, null_size: int, seed: int, progress_bar: bool = True\n) -&gt; np.ndarray:\n    \"\"\"Compute p-values for average precision scores based on a null distribution.\n\n    This function calculates the p-values for each profile in the input DataFrame,\n    comparing their average precision scores (`average_precision`) against a null\n    distribution generated for their specific configurations (number of positive\n    and total pairs). Profiles with no positive pairs are excluded from the p-value calculation.\n\n    Parameters\n    ----------\n    dframe : pd.DataFrame\n        A DataFrame containing the following columns:\n        - `average_precision`: The AP scores for each profile.\n        - `n_pos_pairs`: Number of positive pairs for each profile.\n        - `n_total_pairs`: Total number of pairs (positive + negative) for each profile.\n    null_size : int\n        The number of samples to generate in the null distribution for significance testing.\n    seed : int\n        Random seed for reproducibility of the null distribution.\n    progress_bar : bool\n        Whether or not to show tqdm's progress bar.\n\n    Returns\n    -------\n    np.ndarray\n        An array of p-values for each profile in the DataFrame. Profiles with no positive\n        pairs will have NaN as their p-value.\n    \"\"\"\n    # Create a mask to filter profiles with at least one positive pair\n    mask = dframe[\"n_pos_pairs\"] &gt; 0\n\n    # Initialize the p-values array with NaN for all profiles\n    pvals = np.full(len(dframe), np.nan, dtype=np.float32)\n\n    # Extract the average precision scores and null configurations for valid profiles\n    scores = dframe.loc[mask, \"average_precision\"].values\n    null_confs = dframe.loc[mask, [\"n_pos_pairs\", \"n_total_pairs\"]].values\n\n    # Compute p-values for profiles with valid configurations using the null distribution\n    pvals[mask] = compute.p_values(scores, null_confs, null_size, seed, progress_bar)\n\n    # Return the array of p-values, including NaN for invalid profiles\n    return pvals\n</code></pre>"},{"location":"api/map/#copairs.map.filter","title":"<code>filter</code>","text":"<p>Functions to support query-like syntax when finding the matches.</p>"},{"location":"api/map/#copairs.map.filter.apply_filters","title":"<code>apply_filters(df, query_list)</code>","text":"<p>Combine and apply query filters to a DataFrame.</p> <p>This function takes a list of query expressions and applies them to a DataFrame to filter its rows. If no query expressions are provided, the original DataFrame is returned unchanged.</p> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>The DataFrame to which the filters will be applied.</p> </li> <li> <code>query_list</code>               (<code>List[str]</code>)           \u2013            <p>A list of query expressions (e.g., \"column_name &gt; 5\"). These expressions should follow the syntax supported by <code>pd.DataFrame.query</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The DataFrame filtered based on the provided query expressions.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError:</code>             \u2013            <ul> <li>If the combined query results in an empty DataFrame.</li> <li>If the combined query expression is invalid.</li> </ul> </li> </ul> Source code in <code>src/copairs/map/filter.py</code> <pre><code>def apply_filters(df: pd.DataFrame, query_list: List[str]) -&gt; pd.DataFrame:\n    \"\"\"Combine and apply query filters to a DataFrame.\n\n    This function takes a list of query expressions and applies them to a DataFrame\n    to filter its rows. If no query expressions are provided, the original DataFrame\n    is returned unchanged.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The DataFrame to which the filters will be applied.\n    query_list : List[str]\n        A list of query expressions (e.g., \"column_name &gt; 5\"). These expressions\n        should follow the syntax supported by `pd.DataFrame.query`.\n\n    Returns\n    -------\n    pd.DataFrame\n        The DataFrame filtered based on the provided query expressions.\n\n    Raises\n    ------\n    ValueError:\n        - If the combined query results in an empty DataFrame.\n        - If the combined query expression is invalid.\n    \"\"\"\n    # If no queries are provided, return the original DataFrame unchanged\n    if not query_list:\n        return df\n\n    # Combine the query expressions into a single string using logical AND (&amp;)\n    combined_query = \" &amp; \".join(f\"({query})\" for query in query_list)\n\n    try:\n        # Apply the combined query to filter the DataFrame\n        df_filtered = df.query(combined_query)\n\n        # Raise an error if the filtered DataFrame is empty\n        if df_filtered.empty:\n            raise ValueError(f\"No data matched the query: {combined_query}\")\n    except Exception as e:\n        # Handle any issues with the query expression and provide feedback\n        raise ValueError(\n            f\"Invalid combined query expression: {combined_query}. Error: {e}\"\n        )\n\n    # Return the filtered DataFrame\n    return df_filtered\n</code></pre>"},{"location":"api/map/#copairs.map.filter.evaluate_and_filter","title":"<code>evaluate_and_filter(df, columns)</code>","text":"<p>Evaluate query filters and filter the metadata DataFrame based on specified columns.</p> <p>This function processes column specifications, extracts any filter conditions, applies these conditions to the metadata DataFrame, and returns the filtered metadata along with the updated list of columns.</p> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>The metadata DataFrame containing information about profiles to be filtered.</p> </li> <li> <code>columns</code>               (<code>List[str]</code>)           \u2013            <p>A list of metadata column names.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tuple[DataFrame, List[str]]</code>           \u2013            <ul> <li>The filtered metadata DataFrame.</li> <li>The updated list of columns after processing any filter specifications.</li> </ul> </li> </ul> Source code in <code>src/copairs/map/filter.py</code> <pre><code>def evaluate_and_filter(\n    df: pd.DataFrame, columns: List[str]\n) -&gt; Tuple[pd.DataFrame, List[str]]:\n    \"\"\"Evaluate query filters and filter the metadata DataFrame based on specified columns.\n\n    This function processes column specifications, extracts any filter conditions,\n    applies these conditions to the metadata DataFrame, and returns the filtered metadata\n    along with the updated list of columns.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The metadata DataFrame containing information about profiles to be filtered.\n    columns : List[str]\n        A list of metadata column names.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, List[str]]\n        - The filtered metadata DataFrame.\n        - The updated list of columns after processing any filter specifications.\n    \"\"\"\n    # Extract query filters from the column specifications\n    query_list, columns = extract_filters(columns, df.columns)\n\n    # Apply the extracted filters to the metadata DataFrame\n    df = apply_filters(df, query_list)\n\n    # Return the filtered metadata DataFrame and the updated list of columns\n    return df, columns\n</code></pre>"},{"location":"api/map/#copairs.map.filter.extract_filters","title":"<code>extract_filters(columns, df_columns)</code>","text":"<p>Extract and validate query filters from selected metadata columns.</p> <p>Parameters:</p> <ul> <li> <code>columns</code>               (<code>List[str]</code>)           \u2013            <p>A list of selected metadata column names or query expressions. Query expressions should follow a valid syntax (e.g., \"metadata_column &gt; 5\" or \"metadata_column == 'value'\").</p> </li> <li> <code>df_columns</code>               (<code>List[str]</code>)           \u2013            <p>All available metadata column names to validate against.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tuple[List[str], List[str]]</code>           \u2013            <ul> <li><code>queries_to_eval</code>: A list of valid query expressions to evaluate.</li> <li><code>parsed_cols</code>: A list of valid metadata column names extracted from the input <code>columns</code>.</li> </ul> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError:</code>             \u2013            <ul> <li>If a metadata column or query expression is invalid (e.g., references a non-existent column).</li> <li>If duplicate queries are found for the same metadata column.</li> </ul> </li> </ul> Source code in <code>src/copairs/map/filter.py</code> <pre><code>def extract_filters(\n    columns: List[str], df_columns: List[str]\n) -&gt; Tuple[List[str], List[str]]:\n    \"\"\"Extract and validate query filters from selected metadata columns.\n\n    Parameters\n    ----------\n    columns : List[str]\n        A list of selected metadata column names or query expressions. Query expressions\n        should follow a valid syntax (e.g., \"metadata_column &gt; 5\" or \"metadata_column == 'value'\").\n    df_columns : List[str]\n        All available metadata column names to validate against.\n\n    Returns\n    -------\n    Tuple[List[str], List[str]]\n        - `queries_to_eval`: A list of valid query expressions to evaluate.\n        - `parsed_cols`: A list of valid metadata column names extracted from the input `columns`.\n\n    Raises\n    ------\n    ValueError:\n        - If a metadata column or query expression is invalid (e.g., references a non-existent column).\n        - If duplicate queries are found for the same metadata column.\n    \"\"\"\n    # Initialize lists to store parsed metadata column names and query expressions\n    parsed_cols = []\n    queries_to_eval = []\n\n    # Iterate through each entry in the selected metadata columns\n    for col in columns:\n        if col in df_columns:\n            # If the entry is a valid metadata column name, add it to parsed_cols\n            parsed_cols.append(col)\n            continue\n\n        # Use regex to extract metadata column names from query expressions\n        column_names = re.findall(r\"(\\w+)\\s*[=&lt;&gt;!]+\", col)\n\n        # Validate the extracted metadata column names against all available metadata columns\n        valid_column_names = [col for col in column_names if col in df_columns]\n        if not valid_column_names:\n            raise ValueError(f\"Invalid query or metadata column name: {col}\")\n\n        # Add valid query expressions and associated metadata columns\n        queries_to_eval.append(col)\n        parsed_cols.extend(valid_column_names)\n\n        # Check for duplicate metadata columns in the parsed list\n        if len(parsed_cols) != len(set(parsed_cols)):\n            raise ValueError(f\"Duplicate queries for column: {col}\")\n\n    # Return the queries to evaluate and the parsed metadata column names\n    return queries_to_eval, parsed_cols\n</code></pre>"},{"location":"api/map/#copairs.map.filter.flatten_str_list","title":"<code>flatten_str_list(*args)</code>","text":"<p>Create a single list with all the params given.</p> Source code in <code>src/copairs/map/filter.py</code> <pre><code>def flatten_str_list(*args):\n    \"\"\"Create a single list with all the params given.\"\"\"\n    columns = set()\n    for col in args:\n        if isinstance(col, str):\n            columns.add(col)\n        elif isinstance(col, dict):\n            columns.update(itertools.chain.from_iterable(col.values()))\n        else:\n            columns.update(col)\n    columns = list(columns)\n    return columns\n</code></pre>"},{"location":"api/map/#copairs.map.filter.validate_pipeline_input","title":"<code>validate_pipeline_input(meta, feats, columns)</code>","text":"<p>Validate the metadata and features for consistency and completeness.</p> <p>Parameters:</p> <ul> <li> <code>meta</code>               (<code>DataFrame</code>)           \u2013            <p>The metadata DataFrame describing the profiles.</p> </li> <li> <code>feats</code>               (<code>ndarray</code>)           \u2013            <p>The feature matrix where rows correspond to profiles in the metadata.</p> </li> <li> <code>columns</code>               (<code>List[str]</code>)           \u2013            <p>List of column names in the metadata to validate for null values.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError:</code>             \u2013            <ul> <li>If any of the specified metadata columns contain null values.</li> <li>If the number of rows in the metadata and features are not equal.</li> <li>If the feature matrix contains null values.</li> </ul> </li> </ul> Source code in <code>src/copairs/map/filter.py</code> <pre><code>def validate_pipeline_input(\n    meta: pd.DataFrame, feats: np.ndarray, columns: List[str]\n) -&gt; None:\n    \"\"\"Validate the metadata and features for consistency and completeness.\n\n    Parameters\n    ----------\n    meta : pd.DataFrame\n        The metadata DataFrame describing the profiles.\n    feats : np.ndarray\n        The feature matrix where rows correspond to profiles in the metadata.\n    columns : List[str]\n        List of column names in the metadata to validate for null values.\n\n    Raises\n    ------\n    ValueError:\n        - If any of the specified metadata columns contain null values.\n        - If the number of rows in the metadata and features are not equal.\n        - If the feature matrix contains null values.\n    \"\"\"\n    # Check for null values in the specified metadata columns\n    if meta[columns].isna().any(axis=None):\n        raise ValueError(\"metadata columns should not have null values.\")\n\n    # Check if the number of rows in metadata matches the feature matrix\n    if len(meta) != len(feats):\n        raise ValueError(\"Metadata and features must have the same number of rows.\")\n\n    # Check for null values in the feature matrix\n    if np.isnan(feats).any():\n        raise ValueError(\"features should not have null values.\")\n</code></pre>"},{"location":"api/map/#copairs.map.map","title":"<code>map</code>","text":"<p>Functions to compute mean average precision.</p>"},{"location":"api/map/#copairs.map.map.mean_average_precision","title":"<code>mean_average_precision(ap_scores, sameby, null_size, threshold, seed, progress_bar=True, max_workers=None, cache_dir=None)</code>","text":"<p>Calculate the Mean Average Precision (mAP) score and associated p-values.</p> <p>This function computes the Mean Average Precision (mAP) score by grouping profiles based on the specified criteria (<code>sameby</code>). It calculates the significance of mAP scores by comparing them to a null distribution and performs multiple testing corrections.</p> <p>Parameters:</p> <ul> <li> <code>ap_scores</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing individual Average Precision (AP) scores and pair statistics (e.g., number of positive pairs <code>n_pos_pairs</code> and total pairs <code>n_total_pairs</code>).</p> </li> <li> <code>sameby</code>               (<code>list or str</code>)           \u2013            <p>Metadata column(s) used to group profiles for mAP calculation.</p> </li> <li> <code>null_size</code>               (<code>int</code>)           \u2013            <p>Number of samples in the null distribution for significance testing.</p> </li> <li> <code>threshold</code>               (<code>float</code>)           \u2013            <p>p-value threshold for identifying significant MaP scores.</p> </li> <li> <code>seed</code>               (<code>int</code>)           \u2013            <p>Random seed for reproducibility.</p> </li> <li> <code>progress_bar</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether or not to show tqdm's progress bar.</p> </li> <li> <code>max_workers</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Number of workers used. Default defined by tqdm's <code>thread_map</code>.</p> </li> <li> <code>cache_dir</code>               (<code>str or Path</code>, default:                   <code>None</code> )           \u2013            <p>Location to save the cache.</p> </li> <li> <code>progress_bar</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether or not to show tqdm's progress bar.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>DataFrame with the following columns: - <code>mean_average_precision</code>: Mean AP score for each group. - <code>p_value</code>: p-value comparing mAP to the null distribution. - <code>corrected_p_value</code>: Adjusted p-value after multiple testing correction. - <code>below_p</code>: Boolean indicating if the p-value is below the threshold. - <code>below_corrected_p</code>: Boolean indicating if the corrected p-value is below the threshold.</p> </li> </ul> Source code in <code>src/copairs/map/map.py</code> <pre><code>def mean_average_precision(\n    ap_scores: pd.DataFrame,\n    sameby: List[str],\n    null_size: int,\n    threshold: float,\n    seed: int,\n    progress_bar: bool = True,\n    max_workers: Optional[int] = None,\n    cache_dir: Optional[Union[str, Path]] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Calculate the Mean Average Precision (mAP) score and associated p-values.\n\n    This function computes the Mean Average Precision (mAP) score by grouping profiles\n    based on the specified criteria (`sameby`). It calculates the significance of mAP\n    scores by comparing them to a null distribution and performs multiple testing\n    corrections.\n\n    Parameters\n    ----------\n    ap_scores : pd.DataFrame\n        DataFrame containing individual Average Precision (AP) scores and pair statistics\n        (e.g., number of positive pairs `n_pos_pairs` and total pairs `n_total_pairs`).\n    sameby : list or str\n        Metadata column(s) used to group profiles for mAP calculation.\n    null_size : int\n        Number of samples in the null distribution for significance testing.\n    threshold : float\n        p-value threshold for identifying significant MaP scores.\n    seed : int\n        Random seed for reproducibility.\n    progress_bar : bool\n        Whether or not to show tqdm's progress bar.\n    max_workers : int\n        Number of workers used. Default defined by tqdm's `thread_map`.\n    cache_dir : str or Path\n        Location to save the cache.\n    progress_bar : bool\n        Whether or not to show tqdm's progress bar.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with the following columns:\n        - `mean_average_precision`: Mean AP score for each group.\n        - `p_value`: p-value comparing mAP to the null distribution.\n        - `corrected_p_value`: Adjusted p-value after multiple testing correction.\n        - `below_p`: Boolean indicating if the p-value is below the threshold.\n        - `below_corrected_p`: Boolean indicating if the corrected p-value is below the threshold.\n    \"\"\"\n    # Filter out invalid or incomplete AP scores\n    ap_scores = ap_scores.query(\"~average_precision.isna() and n_pos_pairs &gt; 0\")\n    ap_scores = ap_scores.reset_index(drop=True).copy()\n\n    logger.info(\"Computing null_dist...\")\n    # Extract configurations for null distribution generation\n    null_confs = ap_scores[[\"n_pos_pairs\", \"n_total_pairs\"]].values\n    null_confs, rev_ix = np.unique(null_confs, axis=0, return_inverse=True)\n\n    # Generate null distributions for each unique configuration\n    null_dists = compute.get_null_dists(\n        null_confs, null_size, seed=seed, cache_dir=cache_dir, progress_bar=progress_bar\n    )\n    ap_scores[\"null_ix\"] = rev_ix\n\n    # Function to calculate the p-value for a mAP score based on the null distribution\n    def get_p_value(params):\n        map_score, indices = params\n        null_dist = null_dists[rev_ix[indices]].mean(axis=0)\n        num = (null_dist &gt; map_score).sum()\n        p_value = (num + 1) / (null_size + 1)  # Add 1 for stability\n        return p_value\n\n    logger.info(\"Computing p-values...\")\n\n    # Group by the specified metadata column(s) and calculate mean AP\n    map_scores = ap_scores.groupby(sameby, observed=True, as_index=False).agg(\n        {\n            \"average_precision\": [\"mean\", lambda x: list(x.index)],\n        }\n    )\n    map_scores.columns = sameby + [\"mean_average_precision\", \"indices\"]\n\n    # Compute p-values for each group using the null distributions\n    params = map_scores[[\"mean_average_precision\", \"indices\"]]\n\n    if progress_bar:\n        from tqdm.contrib.concurrent import thread_map\n    else:\n        thread_map = silent_thread_map\n\n    map_scores[\"p_value\"] = thread_map(\n        get_p_value, params.values, leave=False, max_workers=max_workers\n    )\n\n    # Perform multiple testing correction on p-values\n    reject, pvals_corrected, alphacSidak, alphacBonf = multipletests(\n        map_scores[\"p_value\"], method=\"fdr_bh\"\n    )\n    map_scores[\"corrected_p_value\"] = pvals_corrected\n\n    # Mark scores below the p-value threshold\n    map_scores[\"below_p\"] = map_scores[\"p_value\"] &lt; threshold\n    map_scores[\"below_corrected_p\"] = map_scores[\"corrected_p_value\"] &lt; threshold\n\n    return map_scores\n</code></pre>"},{"location":"api/map/#copairs.map.map.silent_thread_map","title":"<code>silent_thread_map(fn, *iterables, **kwargs)</code>","text":"<p>Map iterables and kwargs to a function.</p> <p>Parameters:</p> <ul> <li> <code>fn</code>               (<code>callable</code>)           \u2013            <p>Function to map over iterables.</p> </li> <li> <code>*iterables</code>               (<code>tuple</code>, default:                   <code>()</code> )           \u2013            <p>Iterables to map over.</p> </li> <li> <code>**kwargs</code>               (<code>dict</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments. Accepts: - max_workers : int, optional     Maximum number of workers [default: min(32, cpu_count() + 4)]. - chunksize : int, optional     Size of chunks for each worker [default: 1].</p> </li> </ul> Source code in <code>src/copairs/map/map.py</code> <pre><code>def silent_thread_map(fn, *iterables, **kwargs):\n    \"\"\"Map iterables and kwargs to a function.\n\n    Parameters\n    ----------\n    fn : callable\n        Function to map over iterables.\n    *iterables : tuple\n        Iterables to map over.\n    **kwargs : dict\n        Additional keyword arguments. Accepts:\n        - max_workers : int, optional\n            Maximum number of workers [default: min(32, cpu_count() + 4)].\n        - chunksize : int, optional\n            Size of chunks for each worker [default: 1].\n    \"\"\"\n    # Based on tqdm's original implementation for consistency\n    # (github.com/tqdm/tqdm/blob/0ed5d7f18fa3153834cbac0aa57e8092b217cc16/tqdm/contrib/concurrent.py#L29).\n\n    kwargs = kwargs.copy()\n    max_workers = kwargs.pop(\"max_workers\", min(32, cpu_count() + 4))\n    chunksize = kwargs.pop(\"chunksize\", 1)\n    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n        return list(ex.map(fn, *iterables, chunksize=chunksize, **kwargs))\n</code></pre>"},{"location":"api/map/#copairs.map.multilabel","title":"<code>multilabel</code>","text":"<p>Functions to compute mAP with multilabel support.</p>"},{"location":"api/map/#copairs.map.multilabel.average_precision","title":"<code>average_precision(meta, feats, pos_sameby, pos_diffby, neg_sameby, neg_diffby, multilabel_col, batch_size=20000, distance='cosine', progress_bar=True)</code>","text":"<p>Compute average precision with multilabel support.</p> See Also <p>copairs.map.average_precision : Average precision without multilabel support.</p> Source code in <code>src/copairs/map/multilabel.py</code> <pre><code>def average_precision(\n    meta: pd.DataFrame,\n    feats: pd.DataFrame,\n    pos_sameby: List[str],\n    pos_diffby: List[str],\n    neg_sameby: List[str],\n    neg_diffby: List[str],\n    multilabel_col,\n    batch_size=20000,\n    distance=\"cosine\",\n    progress_bar: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Compute average precision with multilabel support.\n\n    See Also\n    --------\n    copairs.map.average_precision : Average precision without multilabel support.\n    \"\"\"\n    columns = flatten_str_list(pos_sameby, pos_diffby, neg_sameby, neg_diffby)\n    meta, columns = evaluate_and_filter(meta, columns)\n    validate_pipeline_input(meta, feats, columns)\n    distance_fn = compute.get_similarity_fn(distance, progress_bar=progress_bar)\n    # Critical!, otherwise the indexing wont work\n    meta = meta.reset_index(drop=True).copy()\n\n    logger.info(\"Indexing metadata...\")\n\n    logger.info(\"Finding positive pairs...\")\n    pos_pairs, keys, pos_counts = find_pairs_multilabel(\n        meta, sameby=pos_sameby, diffby=pos_diffby, multilabel_col=multilabel_col\n    )\n    if len(pos_pairs) == 0:\n        raise UnpairedException(\"Unable to find positive pairs.\")\n\n    logger.info(\"Finding negative pairs...\")\n    neg_pairs = find_pairs_multilabel(\n        meta, sameby=neg_sameby, diffby=neg_diffby, multilabel_col=multilabel_col\n    )\n    if len(neg_pairs) == 0:\n        raise UnpairedException(\"Unable to find any negative pairs.\")\n\n    logger.info(\"Dropping dups in negative pairs...\")\n    neg_pairs = np.unique(neg_pairs, axis=0)\n\n    logger.info(\"Computing positive similarities...\")\n    pos_sims = distance_fn(feats, pos_pairs, batch_size)\n\n    logger.info(\"Computing negative similarities...\")\n    neg_sims = distance_fn(feats, neg_pairs, batch_size)\n\n    logger.info(\"Computing AP per label...\")\n    negs_for = _create_neg_query_solver(neg_pairs, neg_sims)\n    ap_scores_list, null_confs_list, ix_list = _build_rank_lists_multi(\n        pos_pairs, pos_sims, pos_counts, negs_for\n    )\n\n    logger.info(\"Creating result DataFrame...\")\n    results = []\n    \"Here the positive pairs are per-item inside multilabel_col\"\n    # TODO Check if multi-label key is necessary\n    for i, key in enumerate(keys):\n        result = pd.DataFrame(\n            {\n                \"average_precision\": ap_scores_list[i],\n                \"n_pos_pairs\": null_confs_list[i][:, 0],\n                \"n_total_pairs\": null_confs_list[i][:, 1],\n                \"ix\": ix_list[i],\n                multilabel_col: key,\n            }\n        )\n        results.append(result)\n    results = pd.concat(results).reset_index(drop=True)\n    meta = meta.drop(multilabel_col, axis=1)\n    results = meta.merge(results, right_on=\"ix\", left_index=True).drop(\"ix\", axis=1)\n    results[\"n_pos_pairs\"] = results[\"n_pos_pairs\"].fillna(0).astype(np.uint32)\n    results[\"n_total_pairs\"] = results[\"n_total_pairs\"].fillna(0).astype(np.uint32)\n    logger.info(\"Finished.\")\n    return results\n</code></pre>"},{"location":"api/matching/","title":"copairs.matching","text":""},{"location":"api/matching/#copairs.matching","title":"<code>copairs.matching</code>","text":"<p>Sample pairs with given column restrictions.</p>"},{"location":"api/matching/#copairs.matching.Matcher","title":"<code>Matcher</code>","text":"<p>Class to get pair of rows given contraints in the columns.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>class Matcher:\n    \"\"\"Class to get pair of rows given contraints in the columns.\"\"\"\n\n    def __init__(self, dframe: pd.DataFrame, columns: ColumnList, seed: int):\n        \"\"\"max_size: max number of rows to consider from the same value.\"\"\"\n        rng = np.random.default_rng(seed)\n        self.original_index = dframe.index\n        dframe = dframe[columns].reset_index(drop=True).copy()\n        if (self.original_index == dframe.index).all():\n            self.original_index = None\n        dframe.index.name = \"__copairs_ix\"\n\n        mappers = [reverse_index(dframe[col]) for col in dframe]\n\n        # Create a column order based on the number of potential row matches\n        # Useful to solve queries with more than one sameby\n        n_pairs = {}\n        for mapper in mappers:\n            n_combs = mapper.apply(lambda x: comb(len(x), 2)).sum()\n            n_pairs[mapper.name] = n_combs\n        col_order = sorted(n_pairs, key=n_pairs.get)\n        self.col_order = {column: i for i, column in enumerate(col_order)}\n\n        self.values = dframe[columns].values\n        self.reverse = {mapper.name: mapper.apply(set).to_dict() for mapper in mappers}\n        self.rng = rng\n        self.frozen_valid = frozenset(range(len(self.values)))\n        self.col_to_ix = {c: i for i, c in enumerate(columns)}\n        self.columns = columns\n        self.n_pairs = n_pairs\n        self.rand_iter = iter([])\n\n    def _null_sample(self, diffby_all: ColumnList, diffby_any: ColumnList):\n        \"\"\"Sample a pair from the frame.\"\"\"\n        valid = set(self.frozen_valid)\n        id1 = self.integers(0, len(valid) - 1)\n        valid.remove(id1)\n        valid = self._filter_diffby(id1, diffby_all, diffby_any, valid)\n\n        if len(valid) == 0:\n            # row1 = self.values[id1]\n            # assert np.any(row1 == self.values, axis=1).all()\n            raise UnpairedException(f\"{id1} has no pairs\")\n        id2 = self.choice(list(valid))\n        return id1, id2\n\n    def sample_null_pair(self, diffby: ColumnList, n_tries=5):\n        \"\"\"Sample pairs from the data. It tries multiple times before raising an error.\"\"\"\n        if isinstance(diffby, dict):\n            diffby_all, diffby_any = diffby.get(\"all\", []), diffby.get(\"any\", [])\n            if len(diffby_any) == 1:\n                raise ValueError(\"diffby: any should have more than one column\")\n        else:\n            diffby_all = [diffby] if isinstance(diffby, str) else diffby\n            diffby_any = []\n\n        for _ in range(n_tries):\n            try:\n                return self._null_sample(diffby_all, diffby_any)\n            except UnpairedException:\n                pass\n        raise ValueError(\"Number of tries exhusted. Could not find a valid pair\")\n\n    def rand_next(self):\n        \"\"\"Get next value from the precomputed value.\"\"\"\n        try:\n            value = next(self.rand_iter)\n        except StopIteration:\n            rands = self.rng.uniform(size=int(1e6))\n            self.rand_iter = iter(rands)\n            value = next(self.rand_iter)\n        return value\n\n    def integers(self, min_val, max_val):\n        \"\"\"Get a random integer value between the specified range.\"\"\"\n        return int(self.rand_next() * (max_val - min_val + 1) + min_val)\n\n    def choice(self, items):\n        \"\"\"Select a random item from the given list.\"\"\"\n        min_val, max_val = 0, len(items) - 1\n        pos = self.integers(min_val, max_val)\n        return items[pos]\n\n    def get_all_pairs(\n        self,\n        sameby: Union[str, ColumnList, ColumnDict],\n        diffby: Union[str, ColumnList, ColumnDict],\n        original_index: bool = True,\n    ):\n        \"\"\"Get all pairs with given params.\"\"\"\n        sameby, diffby = self._normalize_sameby_diffby(sameby, diffby)\n        sameby, diffby = self._validate_inputs(sameby, diffby)\n\n        if not sameby[\"all\"] and not sameby[\"any\"]:\n            return self._no_sameby(diffby)\n\n        pairs = dict()\n        if sameby[\"all\"]:\n            pairs = self._sameby_all(sameby, diffby)\n\n        if sameby[\"any\"]:\n            pairs = self._sameby_any(sameby, diffby, pairs)\n\n        if original_index and self.original_index is not None:\n            return self._get_original_index(pairs)\n\n        return pairs\n\n    def _get_original_index(self, pairs):\n        return {\n            k: [tuple(self.original_index[i] for i in p) for p in v]\n            for k, v in pairs.items()\n        }\n\n    def _normalize_sameby_diffby(self, sameby, diffby):\n        \"\"\"Convert sameby and diffby to a consistent format: {'all': [...], 'any': [...]}.\"\"\"\n        keys = [\"all\", \"any\"]\n        result = []\n\n        for param in [sameby, diffby]:\n            param_dict = {key: [] for key in keys}\n            if isinstance(param, dict):\n                for key in keys:\n                    param_dict[key] = param.get(key, [])\n            else:\n                param_list = [param] if isinstance(param, str) else param\n                param_dict[\"all\"] = param_list\n            result.append(param_dict)\n\n        return tuple(result)\n\n    def _validate_inputs(self, sameby, diffby):\n        def validate_condition(condition_dict):\n            new_condition_dict = {\"all\": [], \"any\": []}\n            for key in [\"all\", \"any\"]:\n                for item in condition_dict[key]:\n                    evaluated_columns = self._evaluate_and_filter(item)\n                    new_condition_dict[key].extend(evaluated_columns)\n            return new_condition_dict\n\n        sameby = validate_condition(sameby)\n        diffby = validate_condition(diffby)\n\n        if set(sameby[\"all\"] + sameby[\"any\"]) &amp; set(diffby[\"all\"] + diffby[\"any\"]):\n            raise ValueError(\"sameby and diffby must be disjoint lists\")\n        if not any([sameby[\"all\"], sameby[\"any\"], diffby[\"all\"], diffby[\"any\"]]):\n            raise ValueError(\"sameby, diffby: at least one should be provided\")\n        if len(sameby[\"any\"]) == 1:\n            raise ValueError(\"sameby: any should have more than one column\")\n        if len(diffby[\"any\"]) == 1:\n            raise ValueError(\"diffby: any should have more than one column\")\n\n        return sameby, diffby\n\n    def _evaluate_and_filter(self, item: str) -&gt; list:\n        if item in self.columns:\n            return [item]\n\n        column_names = re.findall(r\"(\\w+)\\s*[=&lt;&gt;!]+\", item)\n        valid_column_names = [col for col in column_names if col in self.columns]\n        if not valid_column_names:\n            raise ValueError(f\"Invalid query or column name: {item}\")\n\n        return valid_column_names\n\n    def _no_sameby(self, diffby):\n        if not diffby[\"any\"]:\n            return self._only_diffby_all(diffby[\"all\"])\n        elif not diffby[\"all\"]:\n            return self._only_diffby_any(diffby[\"any\"])\n        else:\n            return self._only_diffby_all_any(diffby[\"all\"], diffby[\"any\"])\n\n    def _sameby_all(self, sameby, diffby):\n        if len(sameby[\"all\"]) == 1:\n            key = next(iter(sameby[\"all\"]))\n            return self._get_all_pairs_single(key, diffby[\"all\"], diffby[\"any\"])\n        else:\n            ComposedKey = namedtuple(\"ComposedKey\", sameby[\"all\"])\n            sameby[\"all\"] = sorted(sameby[\"all\"], key=self.col_order.get)\n            candidates = self._get_all_pairs_single(\n                sameby[\"all\"][0], diffby[\"all\"], diffby[\"any\"]\n            )\n            col_ix = [self.col_to_ix[col] for col in sameby[\"all\"][1:]]\n\n            pairs = dict()\n            for key, indices in candidates.items():\n                for id1, id2 in indices:\n                    row1 = self.values[id1]\n                    row2 = self.values[id2]\n                    if np.all(row1[col_ix] == row2[col_ix]):\n                        vals = key, *row1[col_ix]\n                        key_tuple = ComposedKey(**dict(zip(sameby[\"all\"], vals)))\n                        pair = (id1, id2)\n                        pairs.setdefault(key_tuple, list()).append(pair)\n\n            return pairs\n\n    def _sameby_any(self, sameby, diffby, pairs):\n        if pairs:\n            pair_values = list(set(itertools.chain.from_iterable(pairs.values())))\n            pair_values = np.asarray([list(pair) for pair in pair_values])\n            pairs_any = self._filter_pairs_by_condition(\n                pair_values, sameby[\"any\"], condition=\"any_same\"\n            )\n            return {\n                k: [p for p in v if p in set(map(tuple, pairs_any))]\n                for k, v in pairs.items()\n            }\n        else:\n            pairs = set()\n            for col in sameby[\"any\"]:\n                col_pairs = self._get_all_pairs_single(\n                    col, diffby[\"all\"], diffby[\"any\"]\n                )\n                pairs.update(set(itertools.chain.from_iterable(col_pairs.values())))\n            pairs = list(pairs)\n            pairs.sort(key=lambda x: (x[0], x[1]))\n            return {None: pairs}\n\n    def _get_all_pairs_single(\n        self, sameby: str, diffby_all: ColumnList, diffby_any: ColumnList\n    ):\n        \"\"\"Get all valid pairs for a single column.\"\"\"\n        mapper = self.reverse[sameby]\n        pairs = dict()\n        for key, rows in mapper.items():\n            processed = set()\n            for id1 in rows:\n                valid = set(rows)\n                processed.add(id1)\n                valid -= processed\n                valid = self._filter_diffby(id1, diffby_all, diffby_any, valid)\n                for id2 in valid:\n                    pair = (id1, id2)\n                    pairs.setdefault(key, list()).append(pair)\n        return pairs\n\n    def _only_diffby_all(self, diffby_all: ColumnList):\n        \"\"\"Generate a dict with single NaN key containing all of the pairs with different values in the column list.\"\"\"\n        diffby_all = sorted(diffby_all, key=self.col_order.get)\n\n        # Cartesian product for one of the diffby columns\n        mapper = self.reverse[diffby_all[0]]\n        pairs = self._get_full_pairs(mapper)\n\n        if len(diffby_all) &gt; 1:\n            pairs = self._filter_pairs_by_condition(\n                pairs, diffby_all[1:], condition=\"all_diff\"\n            )\n\n        pairs = np.unique(pairs, axis=0)\n        return {None: list(map(tuple, pairs))}\n\n    def _only_diffby_any(self, diffby: ColumnList):\n        \"\"\"Generate a dict with single NaN key containing all of the pairs with different values in any of specififed columns.\"\"\"\n        diffby = sorted(diffby, key=self.col_order.get)\n\n        pairs = []\n        for diff_col in diffby:\n            mapper = self.reverse[diff_col]\n            pairs.extend(self._get_full_pairs(mapper))\n\n        pairs = np.sort(np.asarray(pairs))\n        pairs = np.unique(pairs, axis=0)\n        return {None: list(map(tuple, pairs))}\n\n    def _only_diffby_all_any(self, diffby_all: ColumnList, diffby_any: ColumnList):\n        \"\"\"Generate a dict with single NaN key containing all of the pairs with different values in any of specififed columns.\"\"\"\n        diffby_all_pairs = np.asarray(self._only_diffby_all(diffby_all)[None])\n        diffby_all_any = self._filter_pairs_by_condition(\n            diffby_all_pairs, diffby_any, condition=\"any_diff\"\n        )\n        return {None: list(map(tuple, diffby_all_any))}\n\n    def _filter_diffby(\n        self, idx: int, diffby_all: ColumnList, diffby_any: ColumnList, valid: Set[int]\n    ):\n        \"\"\"\n        Remove from valid rows that have matches with idx in any of the diffby columns.\n\n        :idx: index of the row to be compared\n        :diffby: indices of columns that should have different values\n        :valid: candidate rows to be evaluated\n        :returns: subset of valid after removing indices.\n        \"\"\"\n        row = self.values[idx]\n        for col in diffby_all:\n            val = row[self.col_to_ix[col]]\n            if pd.isna(val):\n                continue\n            mapper = self.reverse[col]\n            valid = valid - mapper[val]\n        if diffby_any:\n            mapped = []\n            for col in diffby_any:\n                val = row[self.col_to_ix[col]]\n                if pd.isna(val):\n                    continue\n                mapper = self.reverse[col]\n                mapped.append(mapper[val])\n            if mapped:\n                valid = valid - set.intersection(*mapped)\n        return valid\n\n    def _get_full_pairs(self, mapper):\n        pairs = []\n        for key_a, key_b in itertools.combinations(mapper.keys(), 2):\n            pairs.extend(itertools.product(mapper[key_a], mapper[key_b]))\n        pairs = np.array(pairs)\n        return pairs\n\n    def _filter_pairs_by_condition(self, pairs, columns, condition=\"all_same\"):\n        col_ix = [self.col_to_ix[col] for col in columns]\n        vals_a = self.values[pairs[:, 0]][:, col_ix]\n        vals_b = self.values[pairs[:, 1]][:, col_ix]\n\n        if \"same\" in condition:\n            valid = vals_a == vals_b\n        elif \"diff\" in condition:\n            valid = vals_a != vals_b\n\n        if \"all\" in condition:\n            valid = np.all(valid, axis=1)\n        elif \"any\" in condition:\n            valid = np.any(valid, axis=1)\n\n        return pairs[valid]\n</code></pre>"},{"location":"api/matching/#copairs.matching.Matcher.__init__","title":"<code>__init__(dframe, columns, seed)</code>","text":"<p>max_size: max number of rows to consider from the same value.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def __init__(self, dframe: pd.DataFrame, columns: ColumnList, seed: int):\n    \"\"\"max_size: max number of rows to consider from the same value.\"\"\"\n    rng = np.random.default_rng(seed)\n    self.original_index = dframe.index\n    dframe = dframe[columns].reset_index(drop=True).copy()\n    if (self.original_index == dframe.index).all():\n        self.original_index = None\n    dframe.index.name = \"__copairs_ix\"\n\n    mappers = [reverse_index(dframe[col]) for col in dframe]\n\n    # Create a column order based on the number of potential row matches\n    # Useful to solve queries with more than one sameby\n    n_pairs = {}\n    for mapper in mappers:\n        n_combs = mapper.apply(lambda x: comb(len(x), 2)).sum()\n        n_pairs[mapper.name] = n_combs\n    col_order = sorted(n_pairs, key=n_pairs.get)\n    self.col_order = {column: i for i, column in enumerate(col_order)}\n\n    self.values = dframe[columns].values\n    self.reverse = {mapper.name: mapper.apply(set).to_dict() for mapper in mappers}\n    self.rng = rng\n    self.frozen_valid = frozenset(range(len(self.values)))\n    self.col_to_ix = {c: i for i, c in enumerate(columns)}\n    self.columns = columns\n    self.n_pairs = n_pairs\n    self.rand_iter = iter([])\n</code></pre>"},{"location":"api/matching/#copairs.matching.Matcher.choice","title":"<code>choice(items)</code>","text":"<p>Select a random item from the given list.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def choice(self, items):\n    \"\"\"Select a random item from the given list.\"\"\"\n    min_val, max_val = 0, len(items) - 1\n    pos = self.integers(min_val, max_val)\n    return items[pos]\n</code></pre>"},{"location":"api/matching/#copairs.matching.Matcher.get_all_pairs","title":"<code>get_all_pairs(sameby, diffby, original_index=True)</code>","text":"<p>Get all pairs with given params.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def get_all_pairs(\n    self,\n    sameby: Union[str, ColumnList, ColumnDict],\n    diffby: Union[str, ColumnList, ColumnDict],\n    original_index: bool = True,\n):\n    \"\"\"Get all pairs with given params.\"\"\"\n    sameby, diffby = self._normalize_sameby_diffby(sameby, diffby)\n    sameby, diffby = self._validate_inputs(sameby, diffby)\n\n    if not sameby[\"all\"] and not sameby[\"any\"]:\n        return self._no_sameby(diffby)\n\n    pairs = dict()\n    if sameby[\"all\"]:\n        pairs = self._sameby_all(sameby, diffby)\n\n    if sameby[\"any\"]:\n        pairs = self._sameby_any(sameby, diffby, pairs)\n\n    if original_index and self.original_index is not None:\n        return self._get_original_index(pairs)\n\n    return pairs\n</code></pre>"},{"location":"api/matching/#copairs.matching.Matcher.integers","title":"<code>integers(min_val, max_val)</code>","text":"<p>Get a random integer value between the specified range.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def integers(self, min_val, max_val):\n    \"\"\"Get a random integer value between the specified range.\"\"\"\n    return int(self.rand_next() * (max_val - min_val + 1) + min_val)\n</code></pre>"},{"location":"api/matching/#copairs.matching.Matcher.rand_next","title":"<code>rand_next()</code>","text":"<p>Get next value from the precomputed value.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def rand_next(self):\n    \"\"\"Get next value from the precomputed value.\"\"\"\n    try:\n        value = next(self.rand_iter)\n    except StopIteration:\n        rands = self.rng.uniform(size=int(1e6))\n        self.rand_iter = iter(rands)\n        value = next(self.rand_iter)\n    return value\n</code></pre>"},{"location":"api/matching/#copairs.matching.Matcher.sample_null_pair","title":"<code>sample_null_pair(diffby, n_tries=5)</code>","text":"<p>Sample pairs from the data. It tries multiple times before raising an error.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def sample_null_pair(self, diffby: ColumnList, n_tries=5):\n    \"\"\"Sample pairs from the data. It tries multiple times before raising an error.\"\"\"\n    if isinstance(diffby, dict):\n        diffby_all, diffby_any = diffby.get(\"all\", []), diffby.get(\"any\", [])\n        if len(diffby_any) == 1:\n            raise ValueError(\"diffby: any should have more than one column\")\n    else:\n        diffby_all = [diffby] if isinstance(diffby, str) else diffby\n        diffby_any = []\n\n    for _ in range(n_tries):\n        try:\n            return self._null_sample(diffby_all, diffby_any)\n        except UnpairedException:\n            pass\n    raise ValueError(\"Number of tries exhusted. Could not find a valid pair\")\n</code></pre>"},{"location":"api/matching/#copairs.matching.MatcherMultilabel","title":"<code>MatcherMultilabel</code>","text":"<p>Class to get pair of rows given contraints in the columns.</p> <p>Support one multilabel column.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>class MatcherMultilabel:\n    \"\"\"\n    Class to get pair of rows given contraints in the columns.\n\n    Support one multilabel column.\n    \"\"\"\n\n    def __init__(\n        self, dframe: pd.DataFrame, columns: ColumnList, multilabel_col: str, seed: int\n    ):\n        self.multilabel_col = multilabel_col\n        self.size = dframe.shape[0]\n        self.multilabel_set = dframe[multilabel_col].apply(set)\n        dframe = dframe.explode(multilabel_col)\n        dframe = dframe.reset_index(names=\"__original_index\")\n        self.original_index = dframe[\"__original_index\"]\n        self.matcher = Matcher(dframe, columns, seed)\n\n    def get_all_pairs(self, sameby: Union[str, ColumnList], diffby: ColumnList):\n        \"\"\"Get all pairs with given params.\"\"\"\n        diffby_multi = self.multilabel_col in diffby\n        if diffby_multi:\n            # Multilabel in diffby must be 'ALL' instead of 'ANY'\n            # Doing this filter afterwards\n            diffby = [col for col in diffby if self.multilabel_col != col]\n        if not diffby and not sameby and diffby_multi:\n            return self._only_diffby_multi()\n        pairs = self.matcher.get_all_pairs(sameby, diffby)\n        for key, values in pairs.items():\n            values = np.asarray(values)\n            # Map to original_index\n            values[:, 0] = self.original_index[values[:, 0]]\n            values[:, 1] = self.original_index[values[:, 1]]\n\n            # Check all of the values in the multilabel_col are different\n            if diffby_multi:\n                labels_a = self.multilabel_set.iloc[values[:, 0]]\n                labels_b = self.multilabel_set.iloc[values[:, 1]]\n                valid = [len(a &amp; b) == 0 for a, b in zip(labels_a, labels_b)]\n                values = values[valid]\n            pairs[key] = list(zip(*values.T))\n        return pairs\n\n    def sample_null_pair(self, diffby: ColumnList, n_tries=5):\n        \"\"\"Sample pairs from the data. It tries multiple times before raising an error.\"\"\"\n        null_pair = self.matcher.sample_null_pair(diffby, n_tries)\n        id1, id2 = self.original_index[list(null_pair)].values\n        return id1, id2\n\n    def get_null_pairs(\n        self,\n        diffby: ColumnList,\n        size: int,\n        n_tries=5,\n        progress_bar: bool = True,\n    ):\n        \"\"\"Sample multiple null pairs at the same time.\"\"\"\n        null_pairs = []\n\n        iterator = range(size)\n        if progress_bar:\n            from tqdm.auto import tqdm\n\n            iterator = tqdm(iterator)\n\n        for _ in iterator:\n            null_pairs.append(self.matcher.sample_null_pair(diffby, n_tries))\n        null_pairs = np.array(null_pairs)\n        null_pairs[:, 0] = self.original_index[null_pairs[:, 0]].values\n        null_pairs[:, 1] = self.original_index[null_pairs[:, 1]].values\n        return null_pairs\n\n    def _only_diffby_multi(self):\n        \"\"\"Process special case when it is filter only by the diffby=multilabel_col.\"\"\"\n        pairs = self.get_all_pairs(self.multilabel_col, [])\n        pairs = itertools.chain.from_iterable(pairs.values())\n        pairs = set(map(frozenset, pairs))\n        all_pairs = itertools.combinations(range(self.size), 2)\n\n        def filter_fn(x):\n            return set(x) not in pairs\n\n        return {None: list(filter(filter_fn, all_pairs))}\n</code></pre>"},{"location":"api/matching/#copairs.matching.MatcherMultilabel.get_all_pairs","title":"<code>get_all_pairs(sameby, diffby)</code>","text":"<p>Get all pairs with given params.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def get_all_pairs(self, sameby: Union[str, ColumnList], diffby: ColumnList):\n    \"\"\"Get all pairs with given params.\"\"\"\n    diffby_multi = self.multilabel_col in diffby\n    if diffby_multi:\n        # Multilabel in diffby must be 'ALL' instead of 'ANY'\n        # Doing this filter afterwards\n        diffby = [col for col in diffby if self.multilabel_col != col]\n    if not diffby and not sameby and diffby_multi:\n        return self._only_diffby_multi()\n    pairs = self.matcher.get_all_pairs(sameby, diffby)\n    for key, values in pairs.items():\n        values = np.asarray(values)\n        # Map to original_index\n        values[:, 0] = self.original_index[values[:, 0]]\n        values[:, 1] = self.original_index[values[:, 1]]\n\n        # Check all of the values in the multilabel_col are different\n        if diffby_multi:\n            labels_a = self.multilabel_set.iloc[values[:, 0]]\n            labels_b = self.multilabel_set.iloc[values[:, 1]]\n            valid = [len(a &amp; b) == 0 for a, b in zip(labels_a, labels_b)]\n            values = values[valid]\n        pairs[key] = list(zip(*values.T))\n    return pairs\n</code></pre>"},{"location":"api/matching/#copairs.matching.MatcherMultilabel.get_null_pairs","title":"<code>get_null_pairs(diffby, size, n_tries=5, progress_bar=True)</code>","text":"<p>Sample multiple null pairs at the same time.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def get_null_pairs(\n    self,\n    diffby: ColumnList,\n    size: int,\n    n_tries=5,\n    progress_bar: bool = True,\n):\n    \"\"\"Sample multiple null pairs at the same time.\"\"\"\n    null_pairs = []\n\n    iterator = range(size)\n    if progress_bar:\n        from tqdm.auto import tqdm\n\n        iterator = tqdm(iterator)\n\n    for _ in iterator:\n        null_pairs.append(self.matcher.sample_null_pair(diffby, n_tries))\n    null_pairs = np.array(null_pairs)\n    null_pairs[:, 0] = self.original_index[null_pairs[:, 0]].values\n    null_pairs[:, 1] = self.original_index[null_pairs[:, 1]].values\n    return null_pairs\n</code></pre>"},{"location":"api/matching/#copairs.matching.MatcherMultilabel.sample_null_pair","title":"<code>sample_null_pair(diffby, n_tries=5)</code>","text":"<p>Sample pairs from the data. It tries multiple times before raising an error.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def sample_null_pair(self, diffby: ColumnList, n_tries=5):\n    \"\"\"Sample pairs from the data. It tries multiple times before raising an error.\"\"\"\n    null_pair = self.matcher.sample_null_pair(diffby, n_tries)\n    id1, id2 = self.original_index[list(null_pair)].values\n    return id1, id2\n</code></pre>"},{"location":"api/matching/#copairs.matching.UnpairedException","title":"<code>UnpairedException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when a row can not be paired with any other row in the data.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>class UnpairedException(Exception):\n    \"\"\"Exception raised when a row can not be paired with any other row in the data.\"\"\"\n</code></pre>"},{"location":"api/matching/#copairs.matching.assign_reference_index","title":"<code>assign_reference_index(df, condition, reference_col='Metadata_Reference_Index', default_value=-1, inplace=False)</code>","text":"<p>Assign reference index to a specified column based on a given condition.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def assign_reference_index(\n    df: pd.DataFrame,\n    condition: Union[str, pd.Index],\n    reference_col: str = \"Metadata_Reference_Index\",\n    default_value: int = -1,\n    inplace: bool = False,\n):\n    \"\"\"Assign reference index to a specified column based on a given condition.\"\"\"\n    if not inplace:\n        df = df.copy()\n    df[reference_col] = default_value\n    if isinstance(condition, str):\n        condition = df.query(condition).index\n    df.loc[condition, reference_col] = condition\n    return df if not inplace else None\n</code></pre>"},{"location":"api/matching/#copairs.matching.dict_to_dframe","title":"<code>dict_to_dframe(dict_pairs, sameby)</code>","text":"<p>Convert the Matcher.get_all_pairs output to pd.DataFrame.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def dict_to_dframe(dict_pairs, sameby: Union[str, list]):\n    \"\"\"Convert the Matcher.get_all_pairs output to pd.DataFrame.\"\"\"\n    if not dict_pairs:\n        raise ValueError(\"dict_pairs empty\")\n    keys = np.array(list(dict_pairs.keys()))\n    counts = [len(pairs) for pairs in dict_pairs.values()]\n    keys = np.repeat(keys, counts, axis=0)\n\n    if keys.ndim &gt; 1:\n        # is a ComposedKey\n        keys_df = pd.DataFrame(keys)  # , columns=sameby)\n    else:\n        if isinstance(sameby, list):\n            sameby = sameby[0]\n        keys_df = pd.DataFrame({sameby: keys})\n\n    # Concat all pairs\n    pairs_ix = itertools.chain.from_iterable(dict_pairs.values())\n    pairs_df = pd.DataFrame(pairs_ix, columns=[\"ix1\", \"ix2\"])\n    return pd.concat([keys_df, pairs_df], axis=1)\n</code></pre>"},{"location":"api/matching/#copairs.matching.find_pairs","title":"<code>find_pairs(dframe, sameby, diffby, rev=False)</code>","text":"<p>Find the indices pairs sharing values in <code>sameby</code> columns but not on <code>diffby</code> columns.</p> <p>If <code>rev</code>  is True sameby and diffby are swapped.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def find_pairs(\n    dframe: Union[pd.DataFrame, duckdb.DuckDBPyRelation],\n    sameby: Union[str, ColumnList],\n    diffby: Union[str, ColumnList],\n    rev: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"Find the indices pairs sharing values in `sameby` columns but not on `diffby` columns.\n\n    If `rev`  is True sameby and diffby are swapped.\n    \"\"\"\n    sameby, diffby = _validate(sameby, diffby)\n\n    if len(set(sameby).intersection(diffby)):\n        raise ValueError(\"sameby and diffby must be disjoint lists\")\n\n    df = dframe\n    if isinstance(df, pd.DataFrame):\n        df = dframe.reset_index()\n    with duckdb.connect(\":memory:\"):\n        # If rev is True, diffby and sameby are swapped\n        group_1, group_2 = [\n            [f\"{('', 'NOT')[i - rev]} A.{x} = B.{x}\" for x in y]\n            for i, y in enumerate((sameby, diffby))\n        ]\n        string = (\n            f\"SELECT A.index,B.index\"\n            \" FROM df A\"\n            \" JOIN df B\"\n            \" ON A.index &lt; B.index\"  #  Ensures only one of (a,b)/(b,a) and no (a,a)\n            f\" AND {' AND '.join((*group_1, *group_2))}\"\n        )\n        index_d = duckdb.sql(string).fetchnumpy()\n\n        result = np.array((index_d[\"index\"], index_d[\"index_1\"]), dtype=np.uint32).T\n        return result\n</code></pre>"},{"location":"api/matching/#copairs.matching.find_pairs_multilabel","title":"<code>find_pairs_multilabel(dframe, sameby, diffby, multilabel_col)</code>","text":"<p>Find pairs of rows in a DataFrame that have the same or different values in certain columns.</p> <p>The function takes into account columns with multiple labels (i.e., a list of identifiers).</p> <p>Parameters:</p> <ul> <li> <code>dframe</code>               (<code>Union[DataFrame, DuckDBPyRelation]</code>)           \u2013            <p>Input DataFrame.</p> </li> <li> <code>sameby</code>               (<code>Union[str, ColumnList]</code>)           \u2013            <p>List of column names to consider for finding identical values.</p> </li> <li> <code>diffby</code>               (<code>Union[str, ColumnList]</code>)           \u2013            <p>List of column names to consider for finding different values.</p> </li> <li> <code>multilabel_col</code>               (<code>str</code>)           \u2013            <p>Name of the column containing multiple labels.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>Array of pairs of indices with matching or non-matching values in the specified columns.</p> </li> </ul> Notes <p>The function asserts that <code>multilabel_col</code> is present in either <code>sameby</code> or <code>diffby</code>.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def find_pairs_multilabel(\n    dframe: Union[pd.DataFrame, duckdb.DuckDBPyRelation],\n    sameby: Union[str, ColumnList],\n    diffby: Union[str, ColumnList],\n    multilabel_col: str,\n) -&gt; Union[np.ndarray, Tuple[np.ndarray, np.ndarray, np.ndarray]]:\n    \"\"\"\n    Find pairs of rows in a DataFrame that have the same or different values in certain columns.\n\n    The function takes into account columns with multiple labels (i.e., a list of identifiers).\n\n    Parameters\n    ----------\n    dframe : Union[pd.DataFrame, duckdb.DuckDBPyRelation]\n        Input DataFrame.\n    sameby : Union[str, ColumnList]\n        List of column names to consider for finding identical values.\n    diffby : Union[str, ColumnList]\n        List of column names to consider for finding different values.\n    multilabel_col : str\n        Name of the column containing multiple labels.\n\n    Returns\n    -------\n    np.ndarray\n        Array of pairs of indices with matching or non-matching values in the specified columns.\n\n    Notes\n    -----\n    The function asserts that `multilabel_col` is present in either `sameby` or `diffby`.\n    \"\"\"\n    sameby, diffby = _validate(sameby, diffby)\n    sameby = list(sameby)\n    diffby = list(diffby)\n\n    assert (multilabel_col in sameby) or (multilabel_col in diffby), (\n        f\"Missing {multilabel_col} in sameby and diffby\"\n    )\n\n    df = dframe.reset_index()\n\n    if multilabel_col in sameby:\n        sameby = copy(sameby)\n        sameby.remove(multilabel_col)\n        shared_item = \"\"\n    else:\n        diffby = copy(diffby)\n        diffby.remove(multilabel_col)\n        shared_item = \"NOT\"\n\n    with duckdb.connect(\":memory:\"):\n        result = duckdb.sql(\n            \"SELECT * \"\n            \" FROM (SELECT *,\"\n            f\"list_intersect(A.{multilabel_col},B.{multilabel_col}) AS shared_items\"\n            \" FROM df A JOIN df B ON A.index &lt; B.index)\"\n            f\" WHERE {shared_item} len(shared_items) &gt; 0\"\n        )\n        if len(sameby) or len(diffby):\n            monolabel_result = find_pairs(df, sameby, diffby).T\n            result = duckdb.sql(\n                f\"SELECT *\"\n                \" FROM result A JOIN monolabel_result B\"\n                \" ON A.index = B.column0\"\n                \" AND A.index_1 = B.column1\"\n            )\n\n        if shared_item == \"\":  # If multilabel_col is in sameby\n            counts_col = \"_c\"\n\n            # We assign a pair if any of the other items in the list is a pair too\n            unnested = duckdb.sql(\n                \"SELECT *,UNNEST(shared_items) AS matched_item FROM result\"\n            )\n            string = (\n                \"SELECT * FROM unnested A\"\n                \" NATURAL JOIN (SELECT matched_item,COUNT(matched_item)\"\n                f\" AS {counts_col} FROM unnested GROUP BY matched_item) B\"\n            )\n            results = duckdb.sql(string)\n\n            # Sort them to match the original implementation\n            results = duckdb.sql(\"SELECT * FROM results ORDER BY matched_item\")\n\n            # Sorted pairs of indices (we select to reduce memory footprint)\n            pairs = duckdb.sql(\"SELECT index,index_1 FROM results\")\n            pairs_np = pairs.fetchnumpy()\n\n            # Keys are the items inside multilabel col\n            # Counts are the number of occurrences of each one\n            # It is important to sort again!\n            keys_counts = duckdb.sql(\n                f\"SELECT distinct matched_item,{counts_col} FROM results ORDER BY matched_item\"\n            )\n            keys_counts_np = keys_counts.fetchnumpy()\n\n            result = (\n                np.array(\n                    [pairs_np[f\"index{k}\"] for k in (\"\", \"_1\")], dtype=np.uint32\n                ).T,\n                *[keys_counts_np[k] for k in (\"matched_item\", counts_col)],\n            )\n        else:  # if multilabel_col is in diffby return only the index\n            index_d = result.fetchnumpy()\n            result = np.array(\n                [index_d[k] for k in (\"index\", \"index_1\")], dtype=np.uint32\n            ).T\n\n    return result\n</code></pre>"},{"location":"api/matching/#copairs.matching.reverse_index","title":"<code>reverse_index(col)</code>","text":"<p>Build a reverse_index for a given column in the DataFrame.</p> Source code in <code>src/copairs/matching.py</code> <pre><code>def reverse_index(col: pd.Series) -&gt; pd.Series:\n    \"\"\"Build a reverse_index for a given column in the DataFrame.\"\"\"\n    return pd.Series(col.groupby(col, observed=True).indices, name=col.name)\n</code></pre>"},{"location":"api/plot/","title":"copairs.plot","text":""},{"location":"api/plot/#copairs.plot","title":"<code>copairs.plot</code>","text":"<p>Functions to plot percent replicating.</p>"},{"location":"api/plot/#copairs.plot.plot","title":"<code>plot(corr_score, percent_score, title, left_null_th=None, right_null_th=None, true_dist_title='True replicates', null_dist_title='Null distribution')</code>","text":"<p>Plot two distributions and threshold(s) line.</p> Source code in <code>src/copairs/plot.py</code> <pre><code>def plot(\n    corr_score: CorrelationTestResult,\n    percent_score: float,\n    title: str,\n    left_null_th: Optional[float] = None,\n    right_null_th: Optional[float] = None,\n    true_dist_title=\"True replicates\",\n    null_dist_title=\"Null distribution\",\n) -&gt; go.Figure:\n    \"\"\"Plot two distributions and threshold(s) line.\"\"\"\n    # fig = go.Figure()\n    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n    fig.add_trace(\n        go.Histogram(\n            x=corr_score.corr_dist,\n            nbinsx=20,\n            # histnorm='probability',\n            name=true_dist_title,\n        ),\n        secondary_y=True,\n    )\n    fig.add_trace(\n        go.Histogram(\n            x=corr_score.null_dist,\n            nbinsx=100,\n            # histnorm='probability',\n            name=null_dist_title,\n        )\n    )\n    fig.update_layout(barmode=\"overlay\")\n    fig.update_yaxes(title_text=true_dist_title, secondary_y=True)\n    fig.update_yaxes(title_text=null_dist_title, secondary_y=False)\n\n    for pos, null_th in [(\"left\", left_null_th), (\"right\", right_null_th)]:\n        if null_th:\n            fig.add_vline(\n                x=null_th,\n                line_width=3,\n                line_dash=\"dash\",\n                line_color=\"black\",\n                annotation_text=f\" Null th:{null_th:0.2}\",\n                annotation_position=f\"top {pos}\",\n            )\n\n    fig.update_traces(opacity=0.75, marker_line_width=1)\n    fig.update_layout(\n        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.05, xanchor=\"right\", x=1)\n    )\n    fig.update_layout(\n        font=dict(\n            size=22,\n        )\n    )\n\n    fig.add_annotation(\n        text=f\"{title}: {percent_score:0.1%}\",\n        x=0,\n        y=1.06,\n        showarrow=False,\n        bgcolor=\"#ffffff\",\n        xref=\"paper\",\n        yref=\"paper\",\n        yanchor=\"bottom\",\n        xanchor=\"left\",\n        font=dict(size=20),\n    )\n\n    return fig\n</code></pre>"},{"location":"api/replicating/","title":"copairs.replicating","text":""},{"location":"api/replicating/#copairs.replicating","title":"<code>copairs.replicating</code>","text":"<p>Class for getting Percent replicating metric.</p>"},{"location":"api/replicating/#copairs.replicating.CorrelationTestResult","title":"<code>CorrelationTestResult</code>","text":"<p>Class representing the percent replicating score. It stores distributions.</p> Source code in <code>src/copairs/replicating.py</code> <pre><code>class CorrelationTestResult:\n    \"\"\"Class representing the percent replicating score. It stores distributions.\"\"\"\n\n    def __init__(self, corr_df: pd.DataFrame, null_dist: pd.Series):\n        \"\"\"Initialize object.\"\"\"\n        self.corr_df = corr_df\n        self.corr_dist = corr_df[\"median\"]\n        self.null_dist = null_dist\n\n    def percent_score_left(self):\n        \"\"\"Calculate the percent score using the 5th percentile threshold.\n\n        :return: proportion of correlation distribution beyond the threshold and the threshold.\n        \"\"\"\n        perc_5 = np.nanpercentile(self.null_dist, 5)\n        below_threshold = self.corr_dist.dropna() &lt; perc_5\n        return np.nanmean(below_threshold.astype(float)), perc_5\n\n    def percent_score_right(self):\n        \"\"\"\n        Calculate the percent score using the 95th percentile threshold.\n\n        :return: proportion of correlation distribution beyond the threshold and the threshold.\n        \"\"\"\n        perc_95 = np.nanpercentile(self.null_dist, 95)\n        above_threshold = self.corr_dist.dropna() &gt; perc_95\n        return np.nanmean(above_threshold.astype(float)), perc_95\n\n    def percent_score_both(self):\n        \"\"\"\n        Calculate the percent score using the 5th and 95th percentile or thresholds.\n\n        :return: proportion of correlation distribution beyond the thresholds and the thresholds.\n        \"\"\"\n        perc_95 = np.nanpercentile(self.null_dist, 95)\n        above_threshold = self.corr_dist.dropna() &gt; perc_95\n        perc_5 = np.nanpercentile(self.null_dist, 5)\n        below_threshold = self.corr_dist.dropna() &lt; perc_5\n        return (\n            (\n                np.nanmean(above_threshold.astype(float))\n                + np.nanmean(below_threshold.astype(float))\n            ),\n            perc_5,\n            perc_95,\n        )\n\n    def percent_score(self, how: Literal[\"left\", \"right\", \"both\"]):\n        \"\"\"Calculate percent score given the `how` criteria.\"\"\"\n        left_th, right_th = None, None\n        if how == \"right\":\n            percent_score, right_th = self.percent_score_right()\n        elif how == \"left\":\n            percent_score, left_th = self.percent_score_left()\n        elif how == \"both\":\n            percent_score, left_th, right_th = self.percent_score_both()\n        else:\n            raise ValueError(f\"Invalid value: {how} for how param\")\n\n        return percent_score, left_th, right_th\n\n    def wasserstein_distance(self):\n        \"\"\"Compute the Wasserstein distance between null and corr distributions.\"\"\"\n        from scipy.stats import wasserstein_distance\n\n        return wasserstein_distance(self.null_dist.values, self.corr_dist.values)\n</code></pre>"},{"location":"api/replicating/#copairs.replicating.CorrelationTestResult.__init__","title":"<code>__init__(corr_df, null_dist)</code>","text":"<p>Initialize object.</p> Source code in <code>src/copairs/replicating.py</code> <pre><code>def __init__(self, corr_df: pd.DataFrame, null_dist: pd.Series):\n    \"\"\"Initialize object.\"\"\"\n    self.corr_df = corr_df\n    self.corr_dist = corr_df[\"median\"]\n    self.null_dist = null_dist\n</code></pre>"},{"location":"api/replicating/#copairs.replicating.CorrelationTestResult.percent_score","title":"<code>percent_score(how)</code>","text":"<p>Calculate percent score given the <code>how</code> criteria.</p> Source code in <code>src/copairs/replicating.py</code> <pre><code>def percent_score(self, how: Literal[\"left\", \"right\", \"both\"]):\n    \"\"\"Calculate percent score given the `how` criteria.\"\"\"\n    left_th, right_th = None, None\n    if how == \"right\":\n        percent_score, right_th = self.percent_score_right()\n    elif how == \"left\":\n        percent_score, left_th = self.percent_score_left()\n    elif how == \"both\":\n        percent_score, left_th, right_th = self.percent_score_both()\n    else:\n        raise ValueError(f\"Invalid value: {how} for how param\")\n\n    return percent_score, left_th, right_th\n</code></pre>"},{"location":"api/replicating/#copairs.replicating.CorrelationTestResult.percent_score_both","title":"<code>percent_score_both()</code>","text":"<p>Calculate the percent score using the 5th and 95th percentile or thresholds.</p> <p>:return: proportion of correlation distribution beyond the thresholds and the thresholds.</p> Source code in <code>src/copairs/replicating.py</code> <pre><code>def percent_score_both(self):\n    \"\"\"\n    Calculate the percent score using the 5th and 95th percentile or thresholds.\n\n    :return: proportion of correlation distribution beyond the thresholds and the thresholds.\n    \"\"\"\n    perc_95 = np.nanpercentile(self.null_dist, 95)\n    above_threshold = self.corr_dist.dropna() &gt; perc_95\n    perc_5 = np.nanpercentile(self.null_dist, 5)\n    below_threshold = self.corr_dist.dropna() &lt; perc_5\n    return (\n        (\n            np.nanmean(above_threshold.astype(float))\n            + np.nanmean(below_threshold.astype(float))\n        ),\n        perc_5,\n        perc_95,\n    )\n</code></pre>"},{"location":"api/replicating/#copairs.replicating.CorrelationTestResult.percent_score_left","title":"<code>percent_score_left()</code>","text":"<p>Calculate the percent score using the 5th percentile threshold.</p> <p>:return: proportion of correlation distribution beyond the threshold and the threshold.</p> Source code in <code>src/copairs/replicating.py</code> <pre><code>def percent_score_left(self):\n    \"\"\"Calculate the percent score using the 5th percentile threshold.\n\n    :return: proportion of correlation distribution beyond the threshold and the threshold.\n    \"\"\"\n    perc_5 = np.nanpercentile(self.null_dist, 5)\n    below_threshold = self.corr_dist.dropna() &lt; perc_5\n    return np.nanmean(below_threshold.astype(float)), perc_5\n</code></pre>"},{"location":"api/replicating/#copairs.replicating.CorrelationTestResult.percent_score_right","title":"<code>percent_score_right()</code>","text":"<p>Calculate the percent score using the 95th percentile threshold.</p> <p>:return: proportion of correlation distribution beyond the threshold and the threshold.</p> Source code in <code>src/copairs/replicating.py</code> <pre><code>def percent_score_right(self):\n    \"\"\"\n    Calculate the percent score using the 95th percentile threshold.\n\n    :return: proportion of correlation distribution beyond the threshold and the threshold.\n    \"\"\"\n    perc_95 = np.nanpercentile(self.null_dist, 95)\n    above_threshold = self.corr_dist.dropna() &gt; perc_95\n    return np.nanmean(above_threshold.astype(float)), perc_95\n</code></pre>"},{"location":"api/replicating/#copairs.replicating.CorrelationTestResult.wasserstein_distance","title":"<code>wasserstein_distance()</code>","text":"<p>Compute the Wasserstein distance between null and corr distributions.</p> Source code in <code>src/copairs/replicating.py</code> <pre><code>def wasserstein_distance(self):\n    \"\"\"Compute the Wasserstein distance between null and corr distributions.\"\"\"\n    from scipy.stats import wasserstein_distance\n\n    return wasserstein_distance(self.null_dist.values, self.corr_dist.values)\n</code></pre>"},{"location":"api/replicating/#copairs.replicating.corr_between_non_replicates","title":"<code>corr_between_non_replicates(X, meta, n_samples, n_replicates, diffby, progress_bar=True)</code>","text":"<p>Null distribution between random \"replicates\".</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray</code>)           \u2013            <p>Feature matrix.</p> </li> <li> <code>meta</code>               (<code>DataFrame</code>)           \u2013            <p>Metadata dataframe.</p> </li> <li> <code>n_samples</code>               (<code>int</code>)           \u2013            <p>Number of samples to generate.</p> </li> <li> <code>n_replicates</code>               (<code>int</code>)           \u2013            <p>Number of replicates per sample.</p> </li> <li> <code>diffby</code>               (<code>List[str]</code>)           \u2013            <p>List of columns that should be different.</p> </li> <li> <code>progress_bar</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to show progress bar [default: True].</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Series</code>           \u2013            <p>Correlation values, with a length of <code>n_samples</code>.</p> </li> </ul> Source code in <code>src/copairs/replicating.py</code> <pre><code>def corr_between_non_replicates(\n    X: np.ndarray,\n    meta: pd.DataFrame,\n    n_samples: int,\n    n_replicates: int,\n    diffby: List[str],\n    progress_bar: bool = True,\n):\n    \"\"\"\n    Null distribution between random \"replicates\".\n\n    Parameters\n    ----------\n    X : np.ndarray\n        Feature matrix.\n    meta : pandas.DataFrame\n        Metadata dataframe.\n    n_samples : int\n        Number of samples to generate.\n    n_replicates : int\n        Number of replicates per sample.\n    diffby : List[str]\n        List of columns that should be different.\n    progress_bar : bool, optional\n        Whether to show progress bar [default: True].\n\n    Returns\n    -------\n    pd.Series\n        Correlation values, with a length of `n_samples`.\n    \"\"\"\n    matcher = Matcher(meta, diffby, seed=0)\n    n_pairs = n_replicates * n_samples\n\n    null_pairs = [matcher.sample_null_pair(diffby) for _ in range(n_pairs)]\n    return corr_from_null_pairs(X, null_pairs, n_replicates, progress_bar=progress_bar)\n</code></pre>"},{"location":"api/replicating/#copairs.replicating.corr_between_replicates","title":"<code>corr_between_replicates(X, meta, sameby, diffby, progress_bar=True)</code>","text":"<p>Correlation between replicates.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray</code>)           \u2013            <p>Feature matrix.</p> </li> <li> <code>meta</code>               (<code>DataFrame</code>)           \u2013            <p>Metadata dataframe.</p> </li> <li> <code>sameby</code>               (<code>List[str]</code>)           \u2013            <p>Feature names to group the data frame by.</p> </li> <li> <code>diffby</code>               (<code>List[str]</code>)           \u2013            <p>Feature names to force different values.</p> </li> <li> <code>progress_bar</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to show progress bar [default: True].</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>           \u2013            <p>(DataFrame with correlation statistics, median number of replicates).</p> </li> </ul> Source code in <code>src/copairs/replicating.py</code> <pre><code>def corr_between_replicates(\n    X: np.ndarray,\n    meta: pd.DataFrame,\n    sameby: List[str],\n    diffby: List[str],\n    progress_bar: bool = True,\n):\n    \"\"\"\n    Correlation between replicates.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        Feature matrix.\n    meta : pd.DataFrame\n        Metadata dataframe.\n    sameby : List[str]\n        Feature names to group the data frame by.\n    diffby : List[str]\n        Feature names to force different values.\n    progress_bar : bool, optional\n        Whether to show progress bar [default: True].\n\n    Returns\n    -------\n    tuple\n        (DataFrame with correlation statistics, median number of replicates).\n    \"\"\"\n    matcher = Matcher(meta, sameby + diffby, seed=0)\n    pairs = matcher.get_all_pairs(sameby, diffby)\n    return corr_from_pairs(X, pairs, sameby, progress_bar=progress_bar)\n</code></pre>"},{"location":"api/replicating/#copairs.replicating.corr_from_null_pairs","title":"<code>corr_from_null_pairs(X, null_pairs, n_replicates, progress_bar=True)</code>","text":"<p>Correlation from a given list of unnamed pairs.</p> Source code in <code>src/copairs/replicating.py</code> <pre><code>def corr_from_null_pairs(\n    X: np.ndarray, null_pairs, n_replicates, progress_bar: bool = True\n):\n    \"\"\"Correlation from a given list of unnamed pairs.\"\"\"\n    null_pairs = np.asarray(null_pairs, int)\n    corr_fn = get_similarity_fn(\"correlation\", progress_bar=progress_bar)\n    corrs = corr_fn(X, null_pairs, batch_size=20000)\n    corrs = corrs.reshape(-1, n_replicates)\n    null_dist = np.nanmedian(corrs, axis=1)\n    return pd.Series(null_dist)\n</code></pre>"},{"location":"api/replicating/#copairs.replicating.corr_from_pairs","title":"<code>corr_from_pairs(X, pairs, sameby, progress_bar=True)</code>","text":"<p>Correlation from a list of named pairs. Generated by Matcher.get_all_pairs.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray</code>)           \u2013            </li> <li> <code>pairs</code>               (<code>dict</code>)           \u2013            </li> </ul> <p>Returns:</p> <ul> <li> <code>list-like of correlation values and median of number of replicates</code>           \u2013            </li> </ul> Source code in <code>src/copairs/replicating.py</code> <pre><code>def corr_from_pairs(\n    X: np.ndarray, pairs: dict, sameby: List[str], progress_bar: bool = True\n):\n    \"\"\"\n    Correlation from a list of named pairs. Generated by Matcher.get_all_pairs.\n\n    Parameters\n    ----------\n    X: Matrix containing samples in rows\n    pairs: dictionary with list of index pairs.\n\n    Returns\n    -------\n    list-like of correlation values and median of number of replicates\n    \"\"\"\n    pair_ix = np.vstack(list(pairs.values()))\n    corr_fn = get_similarity_fn(\"correlation\", progress_bar=progress_bar)\n    corrs = corr_fn(X, pair_ix, batch_size=20000)\n    counts = [len(v) for v in pairs.values()]\n\n    if len(sameby) == 1:\n        sameby_vals = np.repeat(list(pairs.keys()), counts)\n    else:\n        sameby_vals = np.repeat(list(map(\"_\".join, pairs.keys())), counts)\n\n    sameby_col = \"_\".join(sameby)\n\n    corrs = pd.DataFrame(\n        {\n            sameby_col: sameby_vals,\n            \"corr\": corrs,\n            \"row_x\": pair_ix[:, 0],\n            \"row_y\": pair_ix[:, 1],\n        }\n    )\n    corrs = corrs.groupby(sameby_col).agg(\n        {\n            \"corr\": [\"median\", \"count\"],\n            \"row_x\": \"nunique\",\n        }\n    )\n\n    median_num_repl = int(corrs[\"row_x\", \"nunique\"].median())\n    corr_dist = corrs[\"corr\"]\n\n    return corr_dist, median_num_repl\n</code></pre>"},{"location":"api/replicating/#copairs.replicating.correlation_test","title":"<code>correlation_test(X, meta, sameby, diffby, n_samples=1000, progress_bar=True)</code>","text":"<p>Generate Null and replicate distribution for replicate correlation analysis.</p> Source code in <code>src/copairs/replicating.py</code> <pre><code>def correlation_test(\n    X: np.ndarray,\n    meta: pd.DataFrame,\n    sameby: List[str],\n    diffby: List[str],\n    n_samples: int = 1000,\n    progress_bar: bool = True,\n) -&gt; CorrelationTestResult:\n    \"\"\"Generate Null and replicate distribution for replicate correlation analysis.\"\"\"\n    corr_df, median_num_repl = corr_between_replicates(\n        X, meta, sameby, diffby, progress_bar=progress_bar\n    )\n\n    n_replicates = min(median_num_repl, 50)\n    null_dist = corr_between_non_replicates(\n        X,\n        meta,\n        n_samples=n_samples,\n        n_replicates=n_replicates,\n        diffby=sameby + diffby,\n        progress_bar=progress_bar,\n    )\n\n    return CorrelationTestResult(corr_df, null_dist)\n</code></pre>"},{"location":"api/replicating/#copairs.replicating.correlation_test_from_pairs","title":"<code>correlation_test_from_pairs(X, pairs, null_pairs, sameby, progress_bar=True)</code>","text":"<p>Generate Null and replicate distribution for replicate correlation analysis.</p> Source code in <code>src/copairs/replicating.py</code> <pre><code>def correlation_test_from_pairs(\n    X: np.ndarray,\n    pairs: dict,\n    null_pairs: list,\n    sameby: list,\n    progress_bar: bool = True,\n) -&gt; CorrelationTestResult:\n    \"\"\"Generate Null and replicate distribution for replicate correlation analysis.\"\"\"\n    corr_df, median_num_repl = corr_from_pairs(\n        X, pairs, sameby, progress_bar=progress_bar\n    )\n    n_replicates = min(median_num_repl, 50)\n    null_dist = corr_from_null_pairs(\n        X, null_pairs, n_replicates, progress_bar=progress_bar\n    )\n    return CorrelationTestResult(corr_df, null_dist)\n</code></pre>"},{"location":"examples/","title":"Overview","text":"<p># Examples</p> <p>Example notebooks demostrating the use of <code>copairs</code>.</p>"},{"location":"examples/#installation","title":"Installation","text":"<p>To install dependencies for running examples, run: <pre><code>pip install copairs[demo]\n</code></pre></p>"},{"location":"examples/#running-examples","title":"Running examples","text":"<pre><code>cd docs/examples\njupyter notebook\n</code></pre>"},{"location":"examples/#list-of-examples","title":"List of examples","text":"<p>We show how to use copairs for:</p> <ul> <li>grouping profiles based on their metadata</li> <li>calculating mAP to assess phenotypic activity of perturbations</li> <li>calculating mAP to assess phenotypic consistency of perturbations</li> <li>estimating null size for mAP p-value calculation</li> </ul>"},{"location":"examples/#data-used","title":"Data used","text":"<p>In these examples, we used a single plate of profiles from the dataset \"cpg0004\" (aka LINCS), which contains Cell Painting images of 1,327 small-molecule perturbations of A549 human cells. The wells on each plate were perturbed with 56 different compounds in six different doses.</p> <p>Way, G. P. et al. Morphology and gene expression profiling provide complementary information for mapping cell state. Cell Syst 13, 911\u2013923.e9 (2022).</p>"},{"location":"examples/finding_pairs/","title":"Finding Pairs","text":"In\u00a0[1]: Copied! <pre>import random\n\nimport pandas as pd\n\nfrom copairs import Matcher, MatcherMultilabel\n</pre> import random  import pandas as pd  from copairs import Matcher, MatcherMultilabel In\u00a0[2]: Copied! <pre>random.seed(0)\nn_samples = 20\ndframe = pd.DataFrame(\n    {\n        \"plate\": [random.choice([\"p1\", \"p2\", \"p3\"]) for _ in range(n_samples)],\n        \"well\": [\n            random.choice([\"w1\", \"w2\", \"w3\", \"w4\", \"w5\"]) for _ in range(n_samples)\n        ],\n        \"label\": [random.choice([\"t1\", \"t2\", \"t3\", \"t4\"]) for _ in range(n_samples)],\n    }\n)\ndframe = dframe.drop_duplicates()\ndframe = dframe.sort_values(by=[\"plate\", \"well\", \"label\"])\ndframe = dframe.reset_index(drop=True)\n</pre> random.seed(0) n_samples = 20 dframe = pd.DataFrame(     {         \"plate\": [random.choice([\"p1\", \"p2\", \"p3\"]) for _ in range(n_samples)],         \"well\": [             random.choice([\"w1\", \"w2\", \"w3\", \"w4\", \"w5\"]) for _ in range(n_samples)         ],         \"label\": [random.choice([\"t1\", \"t2\", \"t3\", \"t4\"]) for _ in range(n_samples)],     } ) dframe = dframe.drop_duplicates() dframe = dframe.sort_values(by=[\"plate\", \"well\", \"label\"]) dframe = dframe.reset_index(drop=True) In\u00a0[3]: Copied! <pre>matcher = Matcher(dframe, [\"plate\", \"well\", \"label\"], seed=0)\npairs_dict = matcher.get_all_pairs(sameby=[\"label\"], diffby=[\"plate\", \"well\"])\npairs_dict\n</pre> matcher = Matcher(dframe, [\"plate\", \"well\", \"label\"], seed=0) pairs_dict = matcher.get_all_pairs(sameby=[\"label\"], diffby=[\"plate\", \"well\"]) pairs_dict Out[3]: <pre>{'t1': [(3, 11), (3, 5), (3, 6), (3, 7)],\n 't2': [(1, 16), (1, 10), (1, 15), (8, 16), (8, 15), (10, 16)],\n 't3': [(9, 4), (9, 13), (13, 4), (13, 12), (4, 12)],\n 't4': [(0, 17), (0, 14), (17, 2), (2, 14)]}</pre> In\u00a0[4]: Copied! <pre>dframe_multi = dframe.groupby([\"plate\", \"well\"])[\"label\"].unique().reset_index()\ndframe_multi\n</pre> dframe_multi = dframe.groupby([\"plate\", \"well\"])[\"label\"].unique().reset_index() dframe_multi Out[4]: plate well label 0 p1 w2 [t4] 1 p1 w3 [t2, t4] 2 p1 w4 [t1, t3] 3 p2 w1 [t1] 4 p2 w2 [t1] 5 p2 w3 [t1, t2, t3] 6 p2 w4 [t2] 7 p2 w5 [t1, t3] 8 p3 w1 [t3, t4] 9 p3 w4 [t2] 10 p3 w5 [t2, t4] In\u00a0[5]: Copied! <pre>matcher_multi = MatcherMultilabel(\n    dframe_multi, columns=[\"plate\", \"well\", \"label\"], multilabel_col=\"label\", seed=0\n)\npairs_multi = matcher_multi.get_all_pairs(sameby=[\"label\"], diffby=[\"plate\", \"well\"])\n</pre> matcher_multi = MatcherMultilabel(     dframe_multi, columns=[\"plate\", \"well\", \"label\"], multilabel_col=\"label\", seed=0 ) pairs_multi = matcher_multi.get_all_pairs(sameby=[\"label\"], diffby=[\"plate\", \"well\"]) <p><code>pairs_multi</code> is also a <code>label_id: pairs</code> dictionary with the same structure discussed before:</p> In\u00a0[6]: Copied! <pre>pairs_multi\n</pre> pairs_multi Out[6]: <pre>{'t1': [(2, 7), (2, 3), (2, 4), (2, 5)],\n 't2': [(1, 10), (1, 6), (1, 9), (5, 10), (5, 9), (6, 10)],\n 't3': [(5, 2), (5, 8), (8, 2), (8, 7), (2, 7)],\n 't4': [(0, 10), (0, 8), (10, 1), (1, 8)]}</pre>"},{"location":"examples/finding_pairs/#matching-profiles-based-on-metadata-columns","title":"Matching profiles based on metadata columns\u00b6","text":"<p>This example demostrates how to use <code>copairs</code> to group profiles based on their metadata properties.</p> <p>Specifically, this is used in calculation of mAP for profile strength and similarity assesement.</p> <p>Citation:</p> <p>Kalinin, A.A., Arevalo, J., Serrano, E., Vulliard, L., Tsang, H., Bornholdt, M., Mu\u00f1oz, A.F., Sivagurunathan, S., Rajwa, B., Carpenter, A.E., Way, G.P. and Singh, S., 2025. A versatile information retrieval framework for evaluating profile strength and similarity. Nature Communications 16, 5181. doi:10.1038/s41467-025-60306-2</p>"},{"location":"examples/finding_pairs/#data","title":"Data\u00b6","text":"<p>Let's assume you have a dataset with 20 samples taken in 3 plates <code>p1, p2, p3</code>, each plate is composed of 5 wells <code>w1, w2, w3, w4, w5</code>, and each well has one or more labels (<code>t1, t2, t3, t4</code>) assigned.</p>"},{"location":"examples/finding_pairs/#getting-valid-pairs","title":"Getting valid pairs\u00b6","text":"<p>To get pairs of samples that share the same <code>label</code> but comes from different <code>plate</code>s at different <code>well</code> positions:</p>"},{"location":"examples/finding_pairs/#getting-valid-pairs-from-a-multilabel-column","title":"Getting valid pairs from a multilabel column\u00b6","text":"<p>For eficiency reasons, you may not want to have duplicated rows. You can group all the labels in a single row and use <code>MatcherMultilabel</code> to find the corresponding pairs:</p>"},{"location":"examples/null_size/","title":"Determining null size for mAP p-value calculation","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.special import comb\n\nfrom copairs import map\n</pre> import numpy as np import pandas as pd import matplotlib.pyplot as plt from scipy.special import comb  from copairs import map In\u00a0[2]: Copied! <pre>def plot_scatter_grid(\n    data,\n    null_size_col=\"null_size\",\n    x_col=\"mAP\",\n    y_col=\"-log10(p-value)\",\n    color_col=\"below_corrected_p\",\n    cmap=\"tab10\",\n    figsize=(12, 6),\n):\n    \"\"\"Plot a grid of scatter plots for different values of a given column.\n\n    Args:\n        data (pd.DataFrame): Input DataFrame containing the data.\n        null_size_col (str): Column to split data into subplots. Defaults to \"null_size\".\n        x_col (str): Column to use for the x-axis. Defaults to \"mean_average_precision\".\n        y_col (str): Column to use for the y-axis. Defaults to \"-log10(p-value)\".\n        color_col (str): Column for coloring points. Defaults to \"below_corrected_p\".\n        cmap (str): Colormap for the scatter plot. Defaults to \"tab10\".\n        figsize (tuple): Figure size. Defaults to (12, 6).\n    \"\"\"\n    unique_null_sizes = sorted(data[null_size_col].unique())  # Get unique values\n    n_rows, n_cols = 3, 4  # Define grid shape\n\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize, sharex=True, sharey=True)\n    axes = axes.flatten()  # Flatten for easy iteration\n\n    for i, null_size in enumerate(unique_null_sizes):\n        ax = axes[i]\n        subset = data[data[null_size_col] == null_size]  # Filter data for current panel\n\n        # Compute active ratio for the subset\n        active_ratio = subset[color_col].mean()\n\n        # Scatter plot\n        _ = ax.scatter(\n            subset[x_col], subset[y_col], c=subset[color_col], cmap=cmap, s=10\n        )\n\n        ax.axhline(\n            -np.log10(0.05), color=\"black\", linestyle=\"--\"\n        )  # Significance threshold\n        ax.set_title(f\"{null_size_col} = {null_size}\")\n\n        # Display active ratio per panel\n        ax.text(\n            0.4,\n            5,\n            f\"Active = {100 * active_ratio:.2f}%\",\n            va=\"center\",\n            ha=\"left\",\n            fontsize=9,\n        )\n\n        if i % n_cols == 0:  # Leftmost column\n            ax.set_ylabel(y_col)\n        if i &gt;= (n_rows - 1) * n_cols:  # Bottom row\n            ax.set_xlabel(x_col)\n\n    fig.suptitle(f\"Scatter plots across different {null_size_col} values\", fontsize=14)\n    plt.tight_layout(rect=[0, 0.05, 1, 0.95])  # Adjust layout\n    plt.show()\n</pre> def plot_scatter_grid(     data,     null_size_col=\"null_size\",     x_col=\"mAP\",     y_col=\"-log10(p-value)\",     color_col=\"below_corrected_p\",     cmap=\"tab10\",     figsize=(12, 6), ):     \"\"\"Plot a grid of scatter plots for different values of a given column.      Args:         data (pd.DataFrame): Input DataFrame containing the data.         null_size_col (str): Column to split data into subplots. Defaults to \"null_size\".         x_col (str): Column to use for the x-axis. Defaults to \"mean_average_precision\".         y_col (str): Column to use for the y-axis. Defaults to \"-log10(p-value)\".         color_col (str): Column for coloring points. Defaults to \"below_corrected_p\".         cmap (str): Colormap for the scatter plot. Defaults to \"tab10\".         figsize (tuple): Figure size. Defaults to (12, 6).     \"\"\"     unique_null_sizes = sorted(data[null_size_col].unique())  # Get unique values     n_rows, n_cols = 3, 4  # Define grid shape      fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize, sharex=True, sharey=True)     axes = axes.flatten()  # Flatten for easy iteration      for i, null_size in enumerate(unique_null_sizes):         ax = axes[i]         subset = data[data[null_size_col] == null_size]  # Filter data for current panel          # Compute active ratio for the subset         active_ratio = subset[color_col].mean()          # Scatter plot         _ = ax.scatter(             subset[x_col], subset[y_col], c=subset[color_col], cmap=cmap, s=10         )          ax.axhline(             -np.log10(0.05), color=\"black\", linestyle=\"--\"         )  # Significance threshold         ax.set_title(f\"{null_size_col} = {null_size}\")          # Display active ratio per panel         ax.text(             0.4,             5,             f\"Active = {100 * active_ratio:.2f}%\",             va=\"center\",             ha=\"left\",             fontsize=9,         )          if i % n_cols == 0:  # Leftmost column             ax.set_ylabel(y_col)         if i &gt;= (n_rows - 1) * n_cols:  # Bottom row             ax.set_xlabel(x_col)      fig.suptitle(f\"Scatter plots across different {null_size_col} values\", fontsize=14)     plt.tight_layout(rect=[0, 0.05, 1, 0.95])  # Adjust layout     plt.show() In\u00a0[3]: Copied! <pre>df_activity = pd.read_csv(\"data/2016_04_01_a549_48hr_batch1_plateSQ00014812.csv\")\nactivity_ap = pd.read_csv(\"data/activity_ap.csv\")\n</pre> df_activity = pd.read_csv(\"data/2016_04_01_a549_48hr_batch1_plateSQ00014812.csv\") activity_ap = pd.read_csv(\"data/activity_ap.csv\") In\u00a0[4]: Copied! <pre># almost all perturbations have 6 replicates\nm = (\n    df_activity.query(\"Metadata_broad_sample != 'DMSO'\")\n    .groupby(\"Metadata_broad_sample\")\n    .size()\n    .mode()[0]\n)\n# the number of control profiles is 24\nn = df_activity.query(\"Metadata_broad_sample == 'DMSO'\").shape[0]\n\n# using SciPy's comb function for numerical stability\nd = comb(m - 1 + n, m - 1, exact=True)\n\nprint(f\"{m=}, {n=}, {d=}\")\n</pre> # almost all perturbations have 6 replicates m = (     df_activity.query(\"Metadata_broad_sample != 'DMSO'\")     .groupby(\"Metadata_broad_sample\")     .size()     .mode()[0] ) # the number of control profiles is 24 n = df_activity.query(\"Metadata_broad_sample == 'DMSO'\").shape[0]  # using SciPy's comb function for numerical stability d = comb(m - 1 + n, m - 1, exact=True)  print(f\"{m=}, {n=}, {d=}\") <pre>m=6, n=24, d=118755\n</pre> <p>For large datasets, computing the full combinatorial null is infeasible. Instead, we approximate the null distribution using Monte Carlo sampling with $d_{\\text{perm}}$ permutations:</p> <p>\\begin{equation}     null\\_size \\approx d_{null} \\end{equation}</p> <p>where $null\\_size$ is the number of random rank list shufflings applied to estimate the null distribution.</p> In\u00a0[5]: Copied! <pre>seed = 0\nnull_cache_dir = \"cache\"  # default is Path.home() / \".copairs\"\n\nactivity_maps = []\nfor ns_pow in range(1, 7):\n    null_size = 10**ns_pow\n\n    replicate_map = map.mean_average_precision(\n        activity_ap,\n        [\"Metadata_broad_sample\"],\n        null_size=null_size,\n        threshold=0.05,\n        seed=seed,\n        cache_dir=null_cache_dir,\n    )\n    replicate_map[\"null_size\"] = null_size\n    activity_maps.append(replicate_map)\n\n    replicate_map = map.mean_average_precision(\n        activity_ap,\n        [\"Metadata_broad_sample\"],\n        null_size=5 * null_size,\n        threshold=0.05,\n        seed=seed,\n        cache_dir=null_cache_dir,\n    )\n    replicate_map[\"null_size\"] = 5 * null_size\n    activity_maps.append(replicate_map)\n\nactivity_maps = pd.concat(activity_maps)\nactivity_maps.rename(columns={\"mean_average_precision\": \"mAP\"}, inplace=True)\nactivity_maps[\"-log10(p-value)\"] = -activity_maps[\"corrected_p_value\"].apply(np.log10)\n\nplot_scatter_grid(activity_maps)\n</pre> seed = 0 null_cache_dir = \"cache\"  # default is Path.home() / \".copairs\"  activity_maps = [] for ns_pow in range(1, 7):     null_size = 10**ns_pow      replicate_map = map.mean_average_precision(         activity_ap,         [\"Metadata_broad_sample\"],         null_size=null_size,         threshold=0.05,         seed=seed,         cache_dir=null_cache_dir,     )     replicate_map[\"null_size\"] = null_size     activity_maps.append(replicate_map)      replicate_map = map.mean_average_precision(         activity_ap,         [\"Metadata_broad_sample\"],         null_size=5 * null_size,         threshold=0.05,         seed=seed,         cache_dir=null_cache_dir,     )     replicate_map[\"null_size\"] = 5 * null_size     activity_maps.append(replicate_map)  activity_maps = pd.concat(activity_maps) activity_maps.rename(columns={\"mean_average_precision\": \"mAP\"}, inplace=True) activity_maps[\"-log10(p-value)\"] = -activity_maps[\"corrected_p_value\"].apply(np.log10)  plot_scatter_grid(activity_maps) <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> <p>Because the full null size $d_{null}=118755$, smaller sample sizes ($&lt;=1,000$) lead to poor estimation of significance for these data, while very large values ($&gt;100,000$) cover the whole null and do not affect perturbation ranking results.</p>"},{"location":"examples/null_size/#determining-null-size-for-map-p-value-calculation","title":"Determining null size for mAP p-value calculation\u00b6","text":""},{"location":"examples/null_size/#load-data","title":"Load data\u00b6","text":"<p>This example relies on data and results from the Phenotypic activity example, so run that one first if you haven't.</p> <p>Let's define some helper functions.</p>"},{"location":"examples/null_size/#complete-null-size","title":"Complete null size\u00b6","text":"<p>We estimate the statistical significance of a mAP score with respect to a random baseline using a permutation testing approach, a non-parametric, assumption-free method for testing the null hypothesis of sample exchangeability. The complete AP null distribution consists of all possible rank list re-shuffles.</p> <p>Let $m$ to be the number of perturbation replicates and $n$ to be the number of control profiles. Given that one perturbation profile serves as a query, the complete null size $d$ can be calculated as a binomial coefficient:</p> <p>\\begin{equation}     d_{null} = \\binom{(m-1)}{(m-1)*n} \\end{equation}</p> <p>Let's calculate the complete null size for the example dataset.</p>"},{"location":"examples/null_size/#effect-of-null-size-on-map-p-value-calculation","title":"Effect of null size on mAP p-value calculation\u00b6","text":"<p>Let's calculate mAP significance on the given dataset using <code>null_size</code> values from $10$ to $5*10^6$ and plot results below.</p> <p>We'll also change the location of cached null distributions from user home to a local subdiretory.</p>"},{"location":"examples/null_size/#practical-consideration-for-choosing-the-null-size","title":"Practical consideration for choosing the null size\u00b6","text":"<p>In practice, drawing a large number of samples is not always feasible, because compute time for each AP calculation grows with the higher number of perturbations of the dataset, the number of metadata constraints for profile grouping, sizes of perturbation groups (the number of perturbation replicates) and control groups (the number of control replicates), and profile dimensionality (the number of features in a profile).</p> <p>Finding a <code>null_size</code> that works for a particular dataset means balancing between test resolution (for example, being able to tell apart vary small p-values) and compute. We provided <code>null_size</code> values for each real-world dataset in Supplemental Materials to our paper\u2014please refer to:</p> <p>Kalinin, A.A., Arevalo, J., Serrano, E., Vulliard, L., Tsang, H., Bornholdt, M., Mu\u00f1oz, A.F., Sivagurunathan, S., Rajwa, B., Carpenter, A.E., Way, G.P. and Singh, S., 2025. A versatile information retrieval framework for evaluating profile strength and similarity. Nature Communications 16, 5181. doi:10.1038/s41467-025-60306-2</p>"},{"location":"examples/phenotypic_activity/","title":"mAP for phenotypic activity assesement","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom copairs import map\nfrom copairs.matching import assign_reference_index\n</pre> import numpy as np import pandas as pd import matplotlib.pyplot as plt  from copairs import map from copairs.matching import assign_reference_index In\u00a0[2]: Copied! <pre># these imports are only needed for showing Figure 1 from the paper\nfrom io import BytesIO\nfrom pathlib import Path\n\nimport requests\nfrom PIL import Image\nfrom IPython.display import display\n</pre> # these imports are only needed for showing Figure 1 from the paper from io import BytesIO from pathlib import Path  import requests from PIL import Image from IPython.display import display In\u00a0[3]: Copied! <pre>fig1_path = \"data/F1.large.jpg\"\nfig1_url = \"https://www.biorxiv.org/content/biorxiv/early/2024/04/02/2024.04.01.587631/F1.large.jpg\"\n\nif not Path(fig1_path).is_file():\n    image = Image.open(BytesIO(requests.get(fig1_url).content))\n    image.save(fig1_path)\n\nimage = Image.open(fig1_path).resize((514, 640))\ndisplay(image)\n</pre> fig1_path = \"data/F1.large.jpg\" fig1_url = \"https://www.biorxiv.org/content/biorxiv/early/2024/04/02/2024.04.01.587631/F1.large.jpg\"  if not Path(fig1_path).is_file():     image = Image.open(BytesIO(requests.get(fig1_url).content))     image.save(fig1_path)  image = Image.open(fig1_path).resize((514, 640)) display(image) In\u00a0[4]: Copied! <pre>local_path = \"data/2016_04_01_a549_48hr_batch1_plateSQ00014812.csv\"\ncommit = \"da8ae6a3bc103346095d61b4ee02f08fc85a5d98\"\nplate = \"SQ00014812\"\nurl = f\"https://media.githubusercontent.com/media/broadinstitute/lincs-cell-painting/{commit}/profiles/2016_04_01_a549_48hr_batch1/{plate}/{plate}_normalized_feature_select.csv.gz\"\n\nif not Path(local_path).is_file():\n    df = pd.read_csv(url)\n    df.to_csv(local_path, index=False)\nelse:\n    df = pd.read_csv(local_path)\n\ndf = df.loc[:, df.nunique() &gt; 1]  # remove constant columns\ndf\n</pre> local_path = \"data/2016_04_01_a549_48hr_batch1_plateSQ00014812.csv\" commit = \"da8ae6a3bc103346095d61b4ee02f08fc85a5d98\" plate = \"SQ00014812\" url = f\"https://media.githubusercontent.com/media/broadinstitute/lincs-cell-painting/{commit}/profiles/2016_04_01_a549_48hr_batch1/{plate}/{plate}_normalized_feature_select.csv.gz\"  if not Path(local_path).is_file():     df = pd.read_csv(url)     df.to_csv(local_path, index=False) else:     df = pd.read_csv(local_path)  df = df.loc[:, df.nunique() &gt; 1]  # remove constant columns df Out[4]: Metadata_broad_sample Metadata_mg_per_ml Metadata_mmoles_per_liter Metadata_pert_id Metadata_pert_mfc_id Metadata_pert_well Metadata_broad_sample_type Metadata_pert_type Metadata_broad_id Metadata_InChIKey14 ... Nuclei_Texture_InverseDifferenceMoment_AGP_5_0 Nuclei_Texture_InverseDifferenceMoment_DNA_20_0 Nuclei_Texture_InverseDifferenceMoment_ER_5_0 Nuclei_Texture_InverseDifferenceMoment_Mito_10_0 Nuclei_Texture_InverseDifferenceMoment_Mito_5_0 Nuclei_Texture_SumAverage_RNA_5_0 Nuclei_Texture_SumEntropy_DNA_10_0 Nuclei_Texture_SumEntropy_DNA_20_0 Nuclei_Texture_SumEntropy_DNA_5_0 Nuclei_Texture_Variance_RNA_10_0 0 DMSO 0.000000 0.000000 NaN NaN A01 control control NaN NaN ... -1.3544 -1.07770 2.26020 -0.377010 -0.065840 2.12360 2.8740 2.87500 2.3047 -0.92358 1 DMSO 0.000000 0.000000 NaN NaN A02 control control NaN NaN ... -2.3840 -0.73440 1.12090 -0.182500 -0.061450 0.66985 2.3919 2.35230 1.8672 -0.11820 2 DMSO 0.000000 0.000000 NaN NaN A03 control control NaN NaN ... -1.9493 -0.36148 0.44050 0.326660 0.547200 0.25015 1.2271 0.77847 1.0651 -0.44810 3 DMSO 0.000000 0.000000 NaN NaN A04 control control NaN NaN ... -2.2909 -0.46380 0.96434 1.132200 0.753500 0.31403 1.4384 1.48110 1.2943 -0.83810 4 DMSO 0.000000 0.000000 NaN NaN A05 control control NaN NaN ... -1.8955 -1.05350 1.64840 0.057781 0.070229 1.60990 1.1296 0.90213 1.1016 0.53225 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 379 BRD-K82746043-001-15-1 3.248700 3.333300 BRD-K82746043 BRD-K82746043-001-15-1 P20 trt trt BRD-K82746043 JLYAXFNOILIKPP ... -6.1522 1.81410 1.54220 -1.874700 -1.133900 1.57540 -3.0962 -3.25160 -2.7683 1.40170 380 BRD-K82746043-001-15-1 1.082900 1.111100 BRD-K82746043 BRD-K82746043-001-15-1 P21 trt trt BRD-K82746043 JLYAXFNOILIKPP ... -5.1586 1.50580 1.68420 -1.126400 -1.066600 1.24740 -1.5305 -1.79020 -1.2474 1.17600 381 BRD-K82746043-001-15-1 0.360970 0.370370 BRD-K82746043 BRD-K82746043-001-15-1 P22 trt trt BRD-K82746043 JLYAXFNOILIKPP ... -5.9475 1.42100 1.51020 -1.103600 -1.666500 1.19840 -2.6086 -2.97620 -2.0026 0.91557 382 BRD-K82746043-001-15-1 0.120320 0.123460 BRD-K82746043 BRD-K82746043-001-15-1 P23 trt trt BRD-K82746043 JLYAXFNOILIKPP ... -8.4408 2.99620 2.55230 -2.275200 -1.783500 2.49200 -4.3964 -4.19030 -3.8360 1.02240 383 BRD-K82746043-001-15-1 0.040108 0.041152 BRD-K82746043 BRD-K82746043-001-15-1 P24 trt trt BRD-K82746043 JLYAXFNOILIKPP ... -7.9510 2.55730 3.05790 -1.466300 -1.673800 1.99540 -4.2176 -4.49940 -3.4922 1.01170 <p>384 rows \u00d7 507 columns</p> <p>Note that in this dataset, pertubations can target multiple genes. We can list these targets from the <code>Metadata_target</code> column.</p> In\u00a0[5]: Copied! <pre>df[\"Metadata_target\"].unique()\n</pre> df[\"Metadata_target\"].unique() Out[5]: <pre>array([nan, 'CHRM1|CHRM2|CHRM3|CHRM4|CHRM5', 'HMGCR',\n       'HDAC1|HDAC2|HDAC3|HDAC9', 'ERBB2', 'DNMT1|DNMT3A',\n       'GABRA1|GABRA2|GABRA3|GABRA4|GABRA5|GABRA6', 'TUBB', 'KIF11',\n       'PSMA1|PSMA2|PSMA3|PSMA4|PSMA5|PSMA6|PSMA7|PSMA8|PSMB1|PSMB10|PSMB11|PSMB2|PSMB3|PSMB4|PSMB5|PSMB6|PSMB7|PSMB8|PSMB9|PSMD1|PSMD2|RELA',\n       'SQLE', 'GABRA1', 'KCNT2|TRPV4', 'AURKA|AURKB',\n       'DRD2|GRIN2A|GRIN2B|GRIN2C|GRIN2D|GRIN3A', 'CFTR',\n       'CACNA1C|CACNA1S|CACNA2D1|CACNG1|HTR3A|KCNA5',\n       'ADRA1A|ADRA1B|ADRA2A|ADRA2B|ADRA2C|CHRM1|CHRM2|CHRM3|CHRM4|CHRM5|DRD1|DRD2|DRD3|DRD4|DRD5|HRH1|HTR1A|HTR1B|HTR1D|HTR1E|HTR2A|HTR2C|HTR3A|HTR6|HTR7',\n       'EGFR|NR1I2', 'ADRA1A|ADRA2A|HRH1|HTR1A|HTR2A|HTR2B|HTR2C|SLC6A4',\n       'EGFR|ERBB2', 'HIF1A', 'ESR1|ESR2|MAP1A|MAP2', 'SCN4A|SCN9A',\n       'BIRC2|XIAP', 'AKT1|AKT2|AKT3|PRKG1', 'ACE',\n       'HTR1A|HTR1B|HTR1D|HTR1E|HTR1F|HTR2A|HTR2B|HTR2C|HTR5A|HTR6|HTR7',\n       'CYSLTR1|CYSLTR2', 'GAST', 'HTR1A', 'PSMB1', 'MET', 'NAE1|UBA3',\n       'VDR', 'HRH1', 'HTR1A|HTR2A', 'AURKA|FLT3|KDR|PDGFRA|PTK2|SRC',\n       'BIRC2|BIRC3|BIRC7|XIAP', 'ABCB1|ABCB4', 'KCNH2',\n       'ABCB11|CAMLG|FPR1|PPIA|PPIF|PPP3CA|PPP3R2|SLC10A1|SLCO1B1|SLCO1B3',\n       'FGFR3|KIT|PDGFRA|PDGFRB', 'FLT3|PIM1|PIM2|PIM3', 'PSEN1',\n       'HSPA1A', 'ATP1A1', 'RELA', 'AVPR1A|AVPR2', 'DPP4',\n       'BCL2|BCL2L1|BCL2L2'], dtype=object)</pre> <p>Here, we treat different doses of each compound as replicates and assess how well we can retrieve them by similarity against the group of negative controls (DMSO).</p> <p>For phenotypic activity, it's helpful to add an extra column that is equal to row index for all DMSO replicates and to -1 for all compound replicates using <code>assign_reference_index</code> function. This helps to not count groups of negative controls as query groups and not consider other perturbations as a reference.</p> In\u00a0[6]: Copied! <pre>reference_col = \"Metadata_reference_index\"\n\ndf_activity = assign_reference_index(\n    df,\n    \"Metadata_broad_sample == 'DMSO'\",  # condition to get reference profiles (neg controls)\n    reference_col=reference_col,\n    default_value=-1,\n)\n</pre> reference_col = \"Metadata_reference_index\"  df_activity = assign_reference_index(     df,     \"Metadata_broad_sample == 'DMSO'\",  # condition to get reference profiles (neg controls)     reference_col=reference_col,     default_value=-1, ) <p>Next, we define the rules by which profiles are grouped based on metadata:</p> <ul> <li><p>Two profiles are a positive pair if they belong to the same group that is not a control group. In this case, any two replicate profiles of the same compound are a positive pair. To define that using metadata columns, positive pairs should share the same value in the metadata column that identifies compounds (<code>Metadata_broad_sample</code>). We add this column to a list names <code>pos_sameby</code>.</p> </li> <li><p>In this case, profiles that form a positive pair do not need to be different in any of the metatada columns, so we keep <code>pos_diffby</code> empty. Although one could define them as being from different batches, for instance, to account for batch effects.</p> </li> <li><p>Two profiles are a negative pair when one of them belongs to a group of compound replicates and another to a group of DMSO controls. That means they should be different both in the metadata column that identifies the specific compound and the reference index columns that we created. The latter is needed to ensure that replicates of compounds are retrieved against only DMSO controls at this stage (and not against replicates of other compounds). We list these columns in <code>neg_diffby</code>.</p> </li> <li><p>Profiles that form a negative pair do not need to be same in any of the metatada columns, so we keep <code>neg_sameby</code> empty.</p> </li> </ul> <p>Finally, we include <code>Metadata_reference_index</code> column to:</p> <ul> <li><code>pos_sameby</code>\u2014this ensures positive pairs connect profiles that share the same value in this column, i.e. a positive pair cannot be formed between any two negative controls (control profiles contain index values).</li> <li><code>neg_diffby</code>\u2014this ensures negative pairs connect profiles that differ in this columns, i.e. a negative pair cannot be formed between profiles of two different perturbations (all perturbation profiles contain -1).</li> </ul> In\u00a0[7]: Copied! <pre># positive pairs are replicates of the same treatment\npos_sameby = [\"Metadata_broad_sample\", reference_col]\npos_diffby = []\n\nneg_sameby = []\n# negative pairs are replicates of different treatments\nneg_diffby = [\"Metadata_broad_sample\", reference_col]\n</pre> # positive pairs are replicates of the same treatment pos_sameby = [\"Metadata_broad_sample\", reference_col] pos_diffby = []  neg_sameby = [] # negative pairs are replicates of different treatments neg_diffby = [\"Metadata_broad_sample\", reference_col] <p>Now we can use <code>average_precision</code> function to calculate the average precision score for each replicate of each compound.</p> <p>It returns metadata with 3 new columns: number of positive and negative pairs for each replicate profile and the average precision score.</p> In\u00a0[8]: Copied! <pre>metadata = df_activity.filter(regex=\"^Metadata\")\nprofiles = df_activity.filter(regex=\"^(?!Metadata)\").values\n\nactivity_ap = map.average_precision(\n    metadata, profiles, pos_sameby, pos_diffby, neg_sameby, neg_diffby\n)\nactivity_ap = activity_ap.query(\"Metadata_broad_sample != 'DMSO'\")  # remove DMSO\nactivity_ap.to_csv(\"data/activity_ap.csv\", index=False)\nactivity_ap\n</pre> metadata = df_activity.filter(regex=\"^Metadata\") profiles = df_activity.filter(regex=\"^(?!Metadata)\").values  activity_ap = map.average_precision(     metadata, profiles, pos_sameby, pos_diffby, neg_sameby, neg_diffby ) activity_ap = activity_ap.query(\"Metadata_broad_sample != 'DMSO'\")  # remove DMSO activity_ap.to_csv(\"data/activity_ap.csv\", index=False) activity_ap <pre>  0%|          | 0/1 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/1 [00:00&lt;?, ?it/s]</pre> Out[8]: Metadata_broad_sample Metadata_mg_per_ml Metadata_mmoles_per_liter Metadata_pert_id Metadata_pert_mfc_id Metadata_pert_well Metadata_broad_sample_type Metadata_pert_type Metadata_broad_id Metadata_InChIKey14 Metadata_moa Metadata_target Metadata_broad_date Metadata_Well Metadata_reference_index n_pos_pairs n_total_pairs average_precision 6 BRD-K74363950-004-01-0 5.655600 10.000000 BRD-K74363950 BRD-K74363950-004-01-0 A07 trt trt BRD-K74363950 ASMXXROZKSBQIH acetylcholine receptor antagonist CHRM1|CHRM2|CHRM3|CHRM4|CHRM5 broad_id_20170327 A07 -1 5 29 0.325013 7 BRD-K74363950-004-01-0 1.885200 3.333300 BRD-K74363950 BRD-K74363950-004-01-0 A08 trt trt BRD-K74363950 ASMXXROZKSBQIH acetylcholine receptor antagonist CHRM1|CHRM2|CHRM3|CHRM4|CHRM5 broad_id_20170327 A08 -1 5 29 0.513889 8 BRD-K74363950-004-01-0 0.628400 1.111100 BRD-K74363950 BRD-K74363950-004-01-0 A09 trt trt BRD-K74363950 ASMXXROZKSBQIH acetylcholine receptor antagonist CHRM1|CHRM2|CHRM3|CHRM4|CHRM5 broad_id_20170327 A09 -1 5 29 0.727778 9 BRD-K74363950-004-01-0 0.209470 0.370370 BRD-K74363950 BRD-K74363950-004-01-0 A10 trt trt BRD-K74363950 ASMXXROZKSBQIH acetylcholine receptor antagonist CHRM1|CHRM2|CHRM3|CHRM4|CHRM5 broad_id_20170327 A10 -1 5 29 0.783333 10 BRD-K74363950-004-01-0 0.069823 0.123460 BRD-K74363950 BRD-K74363950-004-01-0 A11 trt trt BRD-K74363950 ASMXXROZKSBQIH acetylcholine receptor antagonist CHRM1|CHRM2|CHRM3|CHRM4|CHRM5 broad_id_20170327 A11 -1 5 29 0.900000 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 379 BRD-K82746043-001-15-1 3.248700 3.333300 BRD-K82746043 BRD-K82746043-001-15-1 P20 trt trt BRD-K82746043 JLYAXFNOILIKPP BCL inhibitor BCL2|BCL2L1|BCL2L2 broad_id_20170327 P20 -1 5 29 1.000000 380 BRD-K82746043-001-15-1 1.082900 1.111100 BRD-K82746043 BRD-K82746043-001-15-1 P21 trt trt BRD-K82746043 JLYAXFNOILIKPP BCL inhibitor BCL2|BCL2L1|BCL2L2 broad_id_20170327 P21 -1 5 29 0.966667 381 BRD-K82746043-001-15-1 0.360970 0.370370 BRD-K82746043 BRD-K82746043-001-15-1 P22 trt trt BRD-K82746043 JLYAXFNOILIKPP BCL inhibitor BCL2|BCL2L1|BCL2L2 broad_id_20170327 P22 -1 5 29 0.942857 382 BRD-K82746043-001-15-1 0.120320 0.123460 BRD-K82746043 BRD-K82746043-001-15-1 P23 trt trt BRD-K82746043 JLYAXFNOILIKPP BCL inhibitor BCL2|BCL2L1|BCL2L2 broad_id_20170327 P23 -1 5 29 1.000000 383 BRD-K82746043-001-15-1 0.040108 0.041152 BRD-K82746043 BRD-K82746043-001-15-1 P24 trt trt BRD-K82746043 JLYAXFNOILIKPP BCL inhibitor BCL2|BCL2L1|BCL2L2 broad_id_20170327 P24 -1 5 29 1.000000 <p>360 rows \u00d7 18 columns</p> <p>At the next step, we average replicate AP scores at the per-compound level to obtain mAP values using <code>mean_average_precision</code>.</p> <p>It also calculates p-values using permutation testing, and performs FDR correction to compare across compounds.</p> <p>For more information on choosing <code>null size</code> parameter see the Null size example.</p> In\u00a0[9]: Copied! <pre>activity_map = map.mean_average_precision(\n    activity_ap, pos_sameby, null_size=1000000, threshold=0.05, seed=0\n)\nactivity_map[\"-log10(p-value)\"] = -activity_map[\"corrected_p_value\"].apply(np.log10)\nactivity_map.head(10)\n</pre> activity_map = map.mean_average_precision(     activity_ap, pos_sameby, null_size=1000000, threshold=0.05, seed=0 ) activity_map[\"-log10(p-value)\"] = -activity_map[\"corrected_p_value\"].apply(np.log10) activity_map.head(10) <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/58 [00:00&lt;?, ?it/s]</pre> Out[9]: Metadata_broad_sample Metadata_reference_index mean_average_precision indices p_value corrected_p_value below_p below_corrected_p -log10(p-value) 0 BRD-A69275535-001-01-5 -1 0.575629 [96, 97, 98, 99, 100, 101] 1.725598e-02 0.023276 True True 1.633101 1 BRD-A69636825-003-04-7 -1 0.693806 [114, 115, 116, 117, 118, 119] 3.477997e-03 0.006507 True True 2.186605 2 BRD-A69815203-001-07-6 -1 1.000000 [288, 289, 290, 291, 292, 293] 9.999990e-07 0.000008 True True 5.081670 3 BRD-A70858459-001-01-7 -1 0.777173 [156, 157, 158, 159, 160, 161] 8.279992e-04 0.001921 True True 2.716482 4 BRD-A72309220-001-04-1 -1 0.716927 [192, 193, 194, 195, 196, 197] 2.323998e-03 0.004493 True True 2.347458 5 BRD-A72390365-001-15-2 -1 0.934444 [210, 211, 212, 213, 214, 215] 2.799997e-05 0.000108 True True 3.965506 6 BRD-A73368467-003-17-6 -1 0.926032 [246, 247, 248, 249, 250, 251] 3.699996e-05 0.000134 True True 3.872491 7 BRD-A74980173-001-11-9 -1 0.765931 [18, 19, 20, 21, 22, 23] 1.017999e-03 0.002187 True True 2.660188 8 BRD-A81233518-004-16-1 -1 0.621183 [306, 307, 308, 309, 310, 311] 9.594990e-03 0.014269 True True 1.845592 9 BRD-A82035391-001-02-7 -1 0.318066 [342, 343, 344, 345, 346, 347] 2.536767e-01 0.258127 False False 0.588166 <p>Finally, we can plot the results and filter out phenotypicall inactive compounds with corrected p-value &gt;0.05.</p> In\u00a0[10]: Copied! <pre>active_ratio = activity_map.below_corrected_p.mean()\n\nplt.scatter(\n    data=activity_map,\n    x=\"mean_average_precision\",\n    y=\"-log10(p-value)\",\n    c=\"below_corrected_p\",\n    cmap=\"tab10\",\n    s=10,\n)\nplt.title(\"Phenotypic activity assesement\")\nplt.xlabel(\"mAP\")\nplt.ylabel(\"-log10(p-value)\")\nplt.axhline(-np.log10(0.05), color=\"black\", linestyle=\"--\")\nplt.text(\n    0.65,\n    1.5,\n    f\"Phenotypically active = {100 * active_ratio:.2f}%\",\n    va=\"center\",\n    ha=\"left\",\n)\nplt.show()\n</pre> active_ratio = activity_map.below_corrected_p.mean()  plt.scatter(     data=activity_map,     x=\"mean_average_precision\",     y=\"-log10(p-value)\",     c=\"below_corrected_p\",     cmap=\"tab10\",     s=10, ) plt.title(\"Phenotypic activity assesement\") plt.xlabel(\"mAP\") plt.ylabel(\"-log10(p-value)\") plt.axhline(-np.log10(0.05), color=\"black\", linestyle=\"--\") plt.text(     0.65,     1.5,     f\"Phenotypically active = {100 * active_ratio:.2f}%\",     va=\"center\",     ha=\"left\", ) plt.show() In\u00a0[11]: Copied! <pre>activity_map.to_csv(\"data/activity_map.csv\", index=False)\n</pre> activity_map.to_csv(\"data/activity_map.csv\", index=False)"},{"location":"examples/phenotypic_activity/#map-for-phenotypic-activity-assesement","title":"mAP for phenotypic activity assesement\u00b6","text":""},{"location":"examples/phenotypic_activity/#introduction","title":"Introduction\u00b6","text":"<p>This example demostrates how to use <code>copairs</code> to assess phenotypic activity of perturbations in a profiling dataset.</p> <p>Phenotypic activity is assessed by calculating mean average precision (mAP) for the retrieval of replicates of a perturbation against replicates of negative controls.</p> <p>It aims to answer the question: \u201cHow distinguishable is this perturbation from negative controls?\u201d</p> <p>The resulting perturbation mAP score reflects the average extent to which its replicate profiles are more similar to each other compared to control profiles (Figure 1E).</p> <p>Citation:</p> <p>Kalinin, A.A., Arevalo, J., Serrano, E., Vulliard, L., Tsang, H., Bornholdt, M., Mu\u00f1oz, A.F., Sivagurunathan, S., Rajwa, B., Carpenter, A.E., Way, G.P. and Singh, S., 2025. A versatile information retrieval framework for evaluating profile strength and similarity. Nature Communications 16, 5181. doi:10.1038/s41467-025-60306-2</p>"},{"location":"examples/phenotypic_activity/#download-data","title":"Download data\u00b6","text":"<p>Download a single plate of profiles from the dataset \"cpg0004\" (aka LINCS), which contains Cell Painting images of 1,327 small-molecule perturbations of A549 human cells. The wells on each plate were perturbed with 56 different compounds in six different doses.</p> <p>Way, G. P. et al. Morphology and gene expression profiling provide complementary information for mapping cell state. Cell Syst 13, 911\u2013923.e9 (2022).</p>"},{"location":"examples/phenotypic_activity/#assessing-phenotypic-activity-of-compounds-with-map","title":"Assessing phenotypic activity of compounds with mAP\u00b6","text":""},{"location":"examples/phenotypic_consistency/","title":"mAP for phenotypic consistency assesement","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom copairs import map\n</pre> import numpy as np import pandas as pd import matplotlib.pyplot as plt  from copairs import map In\u00a0[2]: Copied! <pre>df = pd.read_csv(\"data/2016_04_01_a549_48hr_batch1_plateSQ00014812.csv\")\nactivity_map = pd.read_csv(\n    \"data/activity_map.csv\"\n)  # load mAP scores for phenotypic activity\n</pre> df = pd.read_csv(\"data/2016_04_01_a549_48hr_batch1_plateSQ00014812.csv\") activity_map = pd.read_csv(     \"data/activity_map.csv\" )  # load mAP scores for phenotypic activity In\u00a0[3]: Copied! <pre># only keep active compounds, i.e. those with corrected p-value &lt; 0.05\nactive_compounds = activity_map.query(\"below_corrected_p\")[\"Metadata_broad_sample\"]\ndf_active = df.query(\"Metadata_broad_sample in @active_compounds\")\ndf_active.head(7)\n</pre> # only keep active compounds, i.e. those with corrected p-value &lt; 0.05 active_compounds = activity_map.query(\"below_corrected_p\")[\"Metadata_broad_sample\"] df_active = df.query(\"Metadata_broad_sample in @active_compounds\") df_active.head(7) Out[3]: Metadata_plate_map_name Metadata_broad_sample Metadata_mg_per_ml Metadata_mmoles_per_liter Metadata_solvent Metadata_pert_id Metadata_pert_mfc_id Metadata_pert_well Metadata_pert_id_vendor Metadata_cell_id ... Nuclei_Texture_InverseDifferenceMoment_AGP_5_0 Nuclei_Texture_InverseDifferenceMoment_DNA_20_0 Nuclei_Texture_InverseDifferenceMoment_ER_5_0 Nuclei_Texture_InverseDifferenceMoment_Mito_10_0 Nuclei_Texture_InverseDifferenceMoment_Mito_5_0 Nuclei_Texture_SumAverage_RNA_5_0 Nuclei_Texture_SumEntropy_DNA_10_0 Nuclei_Texture_SumEntropy_DNA_20_0 Nuclei_Texture_SumEntropy_DNA_5_0 Nuclei_Texture_Variance_RNA_10_0 6 C-7161-01-LM6-022 BRD-K74363950-004-01-0 5.655600 10.000000 DMSO BRD-K74363950 BRD-K74363950-004-01-0 A07 NaN A549 ... -0.51038 -0.76402 1.616400 -0.49600 -0.481360 2.421100 1.10790 1.13820 1.14320 0.329230 7 C-7161-01-LM6-022 BRD-K74363950-004-01-0 1.885200 3.333300 DMSO BRD-K74363950 BRD-K74363950-004-01-0 A08 NaN A549 ... -0.23602 -0.41129 0.304960 0.47884 0.005852 -0.710330 0.41986 -0.23888 0.54949 -0.092826 8 C-7161-01-LM6-022 BRD-K74363950-004-01-0 0.628400 1.111100 DMSO BRD-K74363950 BRD-K74363950-004-01-0 A09 NaN A549 ... -0.52939 -0.54727 0.722570 0.73399 0.223850 0.035842 0.33318 0.39064 0.42969 -0.811390 9 C-7161-01-LM6-022 BRD-K74363950-004-01-0 0.209470 0.370370 DMSO BRD-K74363950 BRD-K74363950-004-01-0 A10 NaN A549 ... -0.58515 -0.41533 0.044874 0.76374 0.062913 -0.656850 0.18149 -0.10960 0.48699 -0.345260 10 C-7161-01-LM6-022 BRD-K74363950-004-01-0 0.069823 0.123460 DMSO BRD-K74363950 BRD-K74363950-004-01-0 A11 NaN A549 ... -0.52686 -0.57823 0.591610 0.85184 0.560370 0.039184 0.59864 0.44123 0.75783 -0.018031 11 C-7161-01-LM6-022 BRD-K74363950-004-01-0 0.023274 0.041152 DMSO BRD-K74363950 BRD-K74363950-004-01-0 A12 NaN A549 ... -0.48060 -1.47220 0.814150 0.79463 0.089249 0.072240 0.91828 0.39626 1.09120 -0.243750 12 C-7161-01-LM6-022 BRD-K75958547-238-01-0 4.615400 10.000000 DMSO BRD-K75958547 BRD-K75958547-238-01-0 A13 NaN A549 ... -5.89680 -0.97404 -5.025000 -10.41400 -6.067500 7.625700 3.31830 3.27410 -2.12240 2.299300 <p>7 rows \u00d7 519 columns</p> In\u00a0[4]: Copied! <pre># aggregate replicates by taking the median of each feature\nfeature_cols = [c for c in df_active.columns if not c.startswith(\"Metadata\")]\ndf_active = df_active.groupby(\n    [\"Metadata_broad_sample\", \"Metadata_target\"], as_index=False\n)[feature_cols].median()\ndf_active[\"Metadata_target\"] = df_active[\"Metadata_target\"].str.split(\"|\")\ndf_active.head()\n</pre> # aggregate replicates by taking the median of each feature feature_cols = [c for c in df_active.columns if not c.startswith(\"Metadata\")] df_active = df_active.groupby(     [\"Metadata_broad_sample\", \"Metadata_target\"], as_index=False )[feature_cols].median() df_active[\"Metadata_target\"] = df_active[\"Metadata_target\"].str.split(\"|\") df_active.head() Out[4]: Metadata_broad_sample Metadata_target Cells_AreaShape_Eccentricity Cells_AreaShape_Extent Cells_AreaShape_FormFactor Cells_AreaShape_Orientation Cells_AreaShape_Solidity Cells_AreaShape_Zernike_0_0 Cells_AreaShape_Zernike_1_1 Cells_AreaShape_Zernike_2_0 ... Nuclei_Texture_InverseDifferenceMoment_AGP_5_0 Nuclei_Texture_InverseDifferenceMoment_DNA_20_0 Nuclei_Texture_InverseDifferenceMoment_ER_5_0 Nuclei_Texture_InverseDifferenceMoment_Mito_10_0 Nuclei_Texture_InverseDifferenceMoment_Mito_5_0 Nuclei_Texture_SumAverage_RNA_5_0 Nuclei_Texture_SumEntropy_DNA_10_0 Nuclei_Texture_SumEntropy_DNA_20_0 Nuclei_Texture_SumEntropy_DNA_5_0 Nuclei_Texture_Variance_RNA_10_0 0 BRD-A69636825-003-04-7 [CACNA1C, CACNA1S, CACNA2D1, CACNG1, HTR3A, KC... -0.326365 0.651610 0.211280 0.092412 0.456915 0.486515 0.435545 0.863160 ... 0.175200 0.557360 -0.859465 0.409045 0.201909 -1.003185 -1.405850 -1.495100 -0.867225 -0.066115 1 BRD-A69815203-001-07-6 [ABCB11, CAMLG, FPR1, PPIA, PPIF, PPP3CA, PPP3... 2.487450 -2.872750 0.616635 -0.451942 -2.260100 -3.300900 0.316320 -1.825400 ... -2.681800 -0.197230 -4.717350 0.644170 1.324100 0.103070 0.986025 1.346200 0.773450 -2.749350 2 BRD-A70858459-001-01-7 [ESR1, ESR2, MAP1A, MAP2] -0.920210 1.461550 0.445630 -0.394235 1.528450 1.116100 -0.054990 1.061270 ... 0.238875 0.326475 0.064563 0.187646 0.200447 -0.695660 0.100225 0.401885 0.114583 -0.245753 3 BRD-A72309220-001-04-1 [HTR1A, HTR1B, HTR1D, HTR1E, HTR1F, HTR2A, HTR... 0.045435 0.099755 0.103628 0.592620 -0.352200 0.202930 -0.059855 -0.353755 ... 1.069575 -0.475915 -0.174002 0.217965 0.090715 -0.154695 0.165235 -0.160191 0.242195 -0.126886 4 BRD-A73368467-003-17-6 [HRH1] -0.062074 -0.314820 0.526190 -0.502485 -0.444675 -0.191225 0.145019 0.018870 ... 0.527805 -1.204250 0.615420 -0.187645 0.321880 1.013235 0.793675 0.682925 1.075500 0.844115 <p>5 rows \u00d7 495 columns</p> <p>Now, we again use metadata columns to define grouping of profiles. Here, we'd like to group those compounds that share a target and assess their similarity against compounds that do not have the same target:</p> <ul> <li><p>Two compound profiles are a positive pair if they share the same target. To define that using metadata columns, positive pairs should share the same value in the metadata column that identifies targets (<code>Metadata_target</code>). We add this column to a list names <code>pos_sameby</code>.</p> </li> <li><p>In this case, profiles that form a positive pair do not need to be different in any of the metatada columns, so we keep <code>pos_diffby</code> empty. Although one could define them as being structurally different, for example.</p> </li> <li><p>Two profiles are a negative pair when do not share a common target. That means they should be different in the metadata column that identifies targets (<code>Metadata_target</code>).</p> </li> <li><p>Profiles that form a negative pair do not need to be same in any of the metatada columns, so we keep <code>neg_sameby</code> empty.</p> </li> </ul> <p>We use <code>map.multilabel.average_precision</code> because each compound can have more than one target. If that's not the case, the standard <code>map.average_precision</code> should be used instead.</p> In\u00a0[5]: Copied! <pre># positive pairs are compounds that share a target\npos_sameby = [\"Metadata_target\"]\npos_diffby = []\n\nneg_sameby = []\n# negative pairs are compounds that do not share a target\nneg_diffby = [\"Metadata_target\"]\n\nmetadata = df_active.filter(regex=\"^Metadata\")\nprofiles = df_active.filter(regex=\"^(?!Metadata)\").values\n\ntarget_aps = map.multilabel.average_precision(\n    metadata,\n    profiles,\n    pos_sameby=pos_sameby,\n    pos_diffby=pos_diffby,\n    neg_sameby=neg_sameby,\n    neg_diffby=neg_diffby,\n    multilabel_col=\"Metadata_target\",\n)\ntarget_aps\n</pre> # positive pairs are compounds that share a target pos_sameby = [\"Metadata_target\"] pos_diffby = []  neg_sameby = [] # negative pairs are compounds that do not share a target neg_diffby = [\"Metadata_target\"]  metadata = df_active.filter(regex=\"^Metadata\") profiles = df_active.filter(regex=\"^(?!Metadata)\").values  target_aps = map.multilabel.average_precision(     metadata,     profiles,     pos_sameby=pos_sameby,     pos_diffby=pos_diffby,     neg_sameby=neg_sameby,     neg_diffby=neg_diffby,     multilabel_col=\"Metadata_target\", ) target_aps <pre>  0%|          | 0/1 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/1 [00:00&lt;?, ?it/s]</pre> Out[5]: Metadata_broad_sample average_precision n_pos_pairs n_total_pairs Metadata_target 52 BRD-A69636825-003-04-7 0.500000 1 42 HTR3A 32 BRD-A72309220-001-04-1 0.406071 4 42 HTR1A 37 BRD-A72309220-001-04-1 0.142857 1 39 HTR1B 39 BRD-A72309220-001-04-1 0.142857 1 39 HTR1D 41 BRD-A72309220-001-04-1 0.142857 1 39 HTR1E ... ... ... ... ... ... 16 BRD-K74363950-004-01-0 0.105128 2 42 CHRM3 19 BRD-K74363950-004-01-0 0.105128 2 42 CHRM4 22 BRD-K74363950-004-01-0 0.105128 2 42 CHRM5 28 BRD-K76908866-001-07-6 0.500000 1 42 ERBB2 61 BRD-K81258678-001-01-0 0.100000 1 42 RELA <p>64 rows \u00d7 5 columns</p> <p>Then, we can compute mAP scores and p-values for each target group.</p> In\u00a0[6]: Copied! <pre>target_maps = map.mean_average_precision(\n    target_aps, pos_sameby, null_size=1000000, threshold=0.05, seed=0\n)\ntarget_maps[\"-log10(p-value)\"] = -target_maps[\"corrected_p_value\"].apply(np.log10)\ntarget_maps.head(10)\n</pre> target_maps = map.mean_average_precision(     target_aps, pos_sameby, null_size=1000000, threshold=0.05, seed=0 ) target_maps[\"-log10(p-value)\"] = -target_maps[\"corrected_p_value\"].apply(np.log10) target_maps.head(10) <pre>  0%|          | 0/15 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/26 [00:00&lt;?, ?it/s]</pre> Out[6]: Metadata_target mean_average_precision indices p_value corrected_p_value below_p below_corrected_p -log10(p-value) 0 ADRA1A 0.250000 [26, 45] 0.112414 0.186114 False False 0.730220 1 ADRA2A 0.250000 [27, 46] 0.112414 0.186114 False False 0.730220 2 AURKA 0.625000 [21, 22] 0.023976 0.103896 True False 0.983402 3 BIRC2 0.060662 [23, 54] 0.380492 0.471085 False False 0.326901 4 CHRM1 0.098420 [11, 28, 57] 0.492938 0.492938 False False 0.307208 5 CHRM2 0.098420 [12, 29, 58] 0.492938 0.492938 False False 0.307208 6 CHRM3 0.098420 [13, 30, 59] 0.492938 0.492938 False False 0.307208 7 CHRM4 0.098420 [14, 31, 60] 0.492938 0.492938 False False 0.307208 8 CHRM5 0.098420 [15, 32, 61] 0.492938 0.492938 False False 0.307208 9 DRD2 0.750000 [25, 33] 0.000670 0.004355 True True 2.361012 <p>Similarly, we can plot the results, where groups of compounds targeting the same gene are called consistent if their corrected p-value &lt; 0.05.</p> In\u00a0[7]: Copied! <pre>consistent_ratio = target_maps.below_corrected_p.mean()\n\nplt.scatter(\n    data=target_maps,\n    x=\"mean_average_precision\",\n    y=\"-log10(p-value)\",\n    c=\"below_corrected_p\",\n    cmap=\"tab10\",\n    s=10,\n)\nplt.xlabel(\"mAP\")\nplt.ylabel(\"-log10(p-value)\")\nplt.axhline(-np.log10(0.05), color=\"black\", linestyle=\"--\")\nplt.text(\n    0.5,\n    1.5,\n    f\"Phenotypically consistent = {100 * consistent_ratio:.2f}%\",\n    va=\"center\",\n    ha=\"left\",\n)\n\nplt.show()\n</pre> consistent_ratio = target_maps.below_corrected_p.mean()  plt.scatter(     data=target_maps,     x=\"mean_average_precision\",     y=\"-log10(p-value)\",     c=\"below_corrected_p\",     cmap=\"tab10\",     s=10, ) plt.xlabel(\"mAP\") plt.ylabel(\"-log10(p-value)\") plt.axhline(-np.log10(0.05), color=\"black\", linestyle=\"--\") plt.text(     0.5,     1.5,     f\"Phenotypically consistent = {100 * consistent_ratio:.2f}%\",     va=\"center\",     ha=\"left\", )  plt.show() <p>Now we can list compounds that are phenotypically active and consistent.</p> <p>Note that in multi-label scenario, when each compound can have multiple targets, the same compound can have \"consistent\" response in respect to one target, but not another.</p> In\u00a0[8]: Copied! <pre>consistent_targets = target_maps.query(\"below_corrected_p\")[\"Metadata_target\"]\nconsistent_compounds = df_active[\n    df_active[\"Metadata_target\"].apply(\n        lambda x: any(t in x for t in consistent_targets)\n    )\n][\"Metadata_broad_sample\"]\n\nprint(f\"Phenotypically consistent targets: {consistent_targets.str.cat(sep=', ')}\")\nprint(f\"Phenotypically consistent compounds: {consistent_compounds.str.cat(sep=', ')}\")\n</pre> consistent_targets = target_maps.query(\"below_corrected_p\")[\"Metadata_target\"] consistent_compounds = df_active[     df_active[\"Metadata_target\"].apply(         lambda x: any(t in x for t in consistent_targets)     ) ][\"Metadata_broad_sample\"]  print(f\"Phenotypically consistent targets: {consistent_targets.str.cat(sep=', ')}\") print(f\"Phenotypically consistent compounds: {consistent_compounds.str.cat(sep=', ')}\") <pre>Phenotypically consistent targets: DRD2, EGFR, HTR3A, PSMB1\nPhenotypically consistent compounds: BRD-A69636825-003-04-7, BRD-K50691590-001-02-2, BRD-K60230970-001-10-0, BRD-K70330367-003-07-9, BRD-K70358946-001-15-7, BRD-K70401845-003-09-6, BRD-K70914287-300-02-8\n</pre>"},{"location":"examples/phenotypic_consistency/#map-for-phenotypic-consistency-assesement","title":"mAP for phenotypic consistency assesement\u00b6","text":""},{"location":"examples/phenotypic_consistency/#introduction","title":"Introduction\u00b6","text":"<p>This example demostrates how to use <code>copairs</code> to assess phenotypic consistncy of perturbations htat target the same gene against other perturbations.</p> <p>Phenotypic consistency is assessed by calculating mean average precision (mAP) for the retrieval of phenotypically active samples that share expected biological similarity (such as chemical mechanisms of action and gene-gene relationships) against other phenotypically active samples that are not biologically similar to the query sample.</p> <p>It aims to answer the question: \u201cHow distinctive is this group of perturbations from other phenotypically active samples that are not biologically similar to the query sample?\u201d</p> <p>The resulting mAP score for a group of perturbations reflects the average extent to which members of this group are more similar to each other compared to other groups (see Figure 1F).</p> <p>Citation:</p> <p>Kalinin, A.A., Arevalo, J., Serrano, E., Vulliard, L., Tsang, H., Bornholdt, M., Mu\u00f1oz, A.F., Sivagurunathan, S., Rajwa, B., Carpenter, A.E., Way, G.P. and Singh, S., 2025. A versatile information retrieval framework for evaluating profile strength and similarity. Nature Communications 16, 5181. doi:10.1038/s41467-025-60306-2</p>"},{"location":"examples/phenotypic_consistency/#load-data","title":"Load data\u00b6","text":"<p>Assessing phenotypic consistency relies on data and results from the Phenotypic activity example, so run that one first if you haven't.</p>"},{"location":"examples/phenotypic_consistency/#assessing-phenotypic-consistency-of-compounds-grouped-by-targets","title":"Assessing phenotypic consistency of compounds grouped by targets\u00b6","text":"<p>First, we are going to filter out compounds that were not phenotypically active using mAP p-values from the previous section.</p> <p>Next, we will aggregate each compound\u2019s replicate profiles into a \"consensus\" profile by taking the median of each feature to reduce profile noise and improve computational efficiency.</p>"}]}